"method","source","description"
"Multi-view to Novel View","Multi-view to Novel View","Multi-view to Novel view: Synthesizing Novel Views with Self-Learned Confidence"
"Pose2Seg (plus ground-truth keypoints)","Pose2Seg (plus ground-truth keypoints)","Pose2Seg: Detection Free Human Instance Segmentation"
"SGPN-CNN","SGPN-CNN","SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation"
"PANet","PANet","Path Aggregation Network for Instance Segmentation"
"ResNeXt-152 + 1 NL block","ResNeXt-152 + 1 NL block","Non-local Neural Networks"
"MS R-CNN + ResNet-101 DCN + FPN ","MS R-CNN + ResNet-101 DCN + FPN ","Mask Scoring R-CNN"
"Mask R-CNN","Mask R-CNN","Mask R-CNN"
"MultiPath Network","MultiPath Network","A MultiPath Network for Object Detection"
"SciBERT (SciVocab)","SciBERT (SciVocab)","SciBERT: Pretrained Contextualized Embeddings for Scientific Text"
"SciBERT (Base Vocab)","SciBERT (Base Vocab)","SciBERT: Pretrained Contextualized Embeddings for Scientific Text"
"bi-LSTM","bi-LSTM","A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature"
"GoogleNet","GoogleNet","Hardness-Aware Deep Metric Learning"
"word-1, 2 POS-1, 2, 3","word-1, 2 POS-1, 2, 3","Identifying Well-formed Natural Language Questions"
"atrous Residual U-Net","atrous Residual U-Net","Learning Attraction Field Representation for Robust Line Segment Detection"
"xDeepFM","xDeepFM","xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems"
"DeepFM","DeepFM","DeepFM: A Factorization-Machine based Neural Network for CTR Prediction"
"PNN*","PNN*","Product-based Neural Networks for User Response Prediction"
"OPNN","OPNN","Product-based Neural Networks for User Response Prediction"
"Wide & Deep (LR & DNN)","Wide & Deep (LR & DNN)","Wide & Deep Learning for Recommender Systems"
"IPNN","IPNN","Product-based Neural Networks for User Response Prediction"
"FNN","FNN","Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction"
"Wide & Deep (FM & DNN)","Wide & Deep (FM & DNN)","Wide & Deep Learning for Recommender Systems"
"DIN + Dice Activation","DIN + Dice Activation","Deep Interest Network for Click-Through Rate Prediction"
"DIN","DIN","Deep Interest Network for Click-Through Rate Prediction"
"PNN","PNN","Product-based Neural Networks for User Response Prediction"
"Wide & Deep","Wide & Deep","Wide & Deep Learning for Recommender Systems"
"CNN","CNN","Predicting city safety perception based on visual image content"
"Random Forest","Random Forest","Early hospital mortality prediction using vital signals"
"Gaussian SVM","Gaussian SVM","Early hospital mortality prediction using vital signals"
"Decision Tree","Decision Tree","Early hospital mortality prediction using vital signals"
"Boosted Trees","Boosted Trees","Early hospital mortality prediction using vital signals"
"K-NN","K-NN","Early hospital mortality prediction using vital signals"
"Logistic regression","Logistic regression","Early hospital mortality prediction using vital signals"
"Linear Discriminant","Linear Discriminant","Early hospital mortality prediction using vital signals"
"Linear SVM","Linear SVM","Early hospital mortality prediction using vital signals"
"PointPillars","PointPillars","PointPillars: Fast Encoders for Object Detection from Point Clouds"
"CNN","CNN","Evaluating surgical skills from kinematic data using convolutional neural networks"
"LGCN sub","LGCN sub","Large-Scale Learnable Graph Convolutional Networks"
"GAT","GAT","Graphite: Iterative Generative Modeling of Graphs"
"MTGAE","MTGAE","Multi-Task Graph Autoencoders"
"DGI","DGI","Deep Graph Infomax"
"alpha-LoNGAE","alpha-LoNGAE","Learning to Make Predictions on Graphs with Autoencoders"
"GCN","GCN","Semi-Supervised Classification with Graph Convolutional Networks"
"ChebNet","ChebNet","Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"
"Planetoid*","Planetoid*","Revisiting Semi-Supervised Learning with Graph Embeddings"
"DeepWalk","DeepWalk","DeepWalk: Online Learning of Social Representations"
"GraphGAN","GraphGAN","GraphGAN: Graph Representation Learning with Generative Adversarial Nets"
"Struc2vec","Struc2vec","struc2vec: Learning Node Representations from Structural Identity"
"node2vec","node2vec","node2vec: Scalable Feature Learning for Networks"
"LINE","LINE","LINE: Large-scale Information Network Embedding"
"Context Based Model","Context Based Model","Context Based Approach for Second Language Acquisition"
"BERT + Small Training","BERT + Small Training","Passage Re-ranking with BERT"
"Duet v2","Duet v2","An Updated Duet Model for Passage Re-ranking"
"Cosine similarity function + C128F feature extractor","Cosine similarity function + C128F feature extractor","Dynamic Few-Shot Visual Learning without Forgetting"
"Prototypical-Nets + C64F feature extractor","Prototypical-Nets + C64F feature extractor","Prototypical Networks for Few-shot Learning"
"MAML++","MAML++","How to train your MAML"
"Baseline++","Baseline++","A Closer Look at Few-shot Classification"
"Reptile + Transduction","Reptile + Transduction","On First-Order Meta-Learning Algorithms"
"MAML","MAML","Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
"Matching Nets + C64F feature extractor","Matching Nets + C64F feature extractor","Matching Networks for One Shot Learning"
"Prototypical-Nets","Prototypical-Nets","Prototypical Networks for Few-shot Learning"
"Memory Mod","Memory Mod","Learning to Remember Rare Events"
"Neural Statistician","Neural Statistician","Towards a Neural Statistician"
"Matching Nets","Matching Nets","Matching Networks for One Shot Learning"
"SJE","SJE","Evaluation of Output Embeddings for Fine-Grained Image Classification"
"Sample Clustering","Sample Clustering","Learning Deep Parsimonious Representations"
"Cosine similarity function + C64F feature extractor","Cosine similarity function + C64F feature extractor","Dynamic Few-Shot Visual Learning without Forgetting"
"PLATIPUS","PLATIPUS","Probabilistic Model-Agnostic Meta-Learning"
"NAN","NAN","Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing"
"MH-Parser","MH-Parser","Multiple-Human Parsing in the Wild"
"Holistic instance-level","Holistic instance-level","Holistic, Instance-Level Human Parsing"
"MNC","MNC","Instance-aware Semantic Segmentation via Multi-task Network Cascades"
"DL","DL","Semantic Instance Segmentation with a Discriminative Loss Function"
"LPRNet basic","LPRNet basic","LPRNet: License Plate Recognition via Deep Neural Networks"
"HorizonNet","HorizonNet","HorizonNet: Learning Room Layout with 1D Representation and Pano Stretch Data Augmentation"
"CFL","CFL","Corners for Layout: End-to-End Layout Recovery from 360 Images"
"DuLa-Net","DuLa-Net","DuLa-Net: A Dual-Projection Network for Estimating Room Layouts from a Single RGB Panorama"
"LayoutNet","LayoutNet","LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image"
"Scan2CAD","Scan2CAD","Scan2CAD: Learning CAD Model Alignment in RGB-D Scans"
"3DMatch","3DMatch","3DMatch: Learning Local Geometric Descriptors from RGB-D Reconstructions"
"Graph2Seq-PGE","Graph2Seq-PGE","Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks"
"GGS-NN","GGS-NN","Gated Graph Sequence Neural Networks"
"Massively Multilingual Sentence Embeddings","Massively Multilingual Sentence Embeddings","Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond"
"Multilingual Sentence Embeddings","Multilingual Sentence Embeddings","Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings"
"Monolingual training data","Monolingual training data","Improving Neural Machine Translation Models with Monolingual Data"
"Transfer Learning from VGG16 trained on Imagenet","Transfer Learning from VGG16 trained on Imagenet","Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks"
"Transfer Learning from AlexNet, VGG-16, GoogLeNet and ResNet50","Transfer Learning from AlexNet, VGG-16, GoogLeNet and ResNet50","Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training Strategies for Document Image Classification"
"AlexNet + spatial pyramidal pooling + image resizing","AlexNet + spatial pyramidal pooling + image resizing","Analysis of Convolutional Neural Networks for Document Image Classification"
"Document section-based models + AlexNet transfer learning","Document section-based models + AlexNet transfer learning","Evaluation of Deep Convolutional Nets for Document Image Classification and Retrieval"
"IIC","IIC","Invariant Information Clustering for Unsupervised Image Classification and Segmentation"
"BN LSTM","BN LSTM","Recurrent Batch Normalization"
"Dilated GRU","Dilated GRU","Dilated Recurrent Neural Networks"
"Full-capacity uRNN","Full-capacity uRNN","Full-Capacity Unitary Recurrent Neural Networks"
"LSTM","LSTM","Unitary Evolution Recurrent Neural Networks"
"iRNN","iRNN","A Simple Way to Initialize Recurrent Networks of Rectified Linear Units"
"St-SS-pGRU","St-SS-pGRU","Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image Classification"
"BASSNet","BASSNet","BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network for Hyperspectral Image Classification"
"CNN-MRF","CNN-MRF","Hyperspectral Image Classification with Markov Random Fields and a Convolutional Neural Network"
"PC-DenseNet-161","PC-DenseNet-161","Pairwise Confusion for Fine-Grained Visual Classification"
"PC Bilinear CNN","PC Bilinear CNN","Pairwise Confusion for Fine-Grained Visual Classification"
" AutoAugment"," AutoAugment","AutoAugment: Learning Augmentation Policies from Data"
"AutoAugment","AutoAugment","AutoAugment: Learning Augmentation Policies from Data"
"WS-DAN","WS-DAN","See Better Before Looking Closer: Weakly Supervised Data Augmentation Network for Fine-Grained Visual Classification"
"MPN-COV","MPN-COV","Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization"
"A3M","A3M","Attribute-Aware Attention Model for Fine-grained Representation Learning"
"GoogLeNet","GoogLeNet","A Large-Scale Car Dataset for Fine-Grained Categorization and Verification"
"AlexNet","AlexNet","A Large-Scale Car Dataset for Fine-Grained Categorization and Verification"
"Inception-V3","Inception-V3","Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning"
"Hierarchical Semantic Embedding","Hierarchical Semantic Embedding","Fine-Grained Representation Learning and Recognition by Exploiting Hierarchical Semantic Embedding"
"RA-CNN","RA-CNN","Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-Grained Image Recognition"
"Bilinear-CNN","Bilinear-CNN","Bilinear CNN Models for Fine-Grained Visual Recognition"
"PS-CNN","PS-CNN","Part-Stacked CNN for Fine-Grained Visual Categorization"
"Part RCNN","Part RCNN","Part-based R-CNNs for Fine-grained Category Detection"
"SWSA","SWSA","There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average"
"Mean Teacher","Mean Teacher","Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"
"VAT+EntMin","VAT+EntMin","Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning"
"VAT","VAT","Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning"
"Pi Model","Pi Model","Temporal Ensembling for Semi-Supervised Learning"
"GAN","GAN","Improved Techniques for Training GANs"
"G-model","G-model","Semi-Supervised Learning with Ladder Networks"
"GPIPE + transfer learning","GPIPE + transfer learning","GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"
"Proxyless-G + co","Proxyless-G + co","ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"
"SENet + ShakeShake + Cutout","SENet + ShakeShake + Cutout","Squeeze-and-Excitation Networks"
"WRN + fixup init + mixup + cutout","WRN + fixup init + mixup + cutout","Fixup Initialization: Residual Learning Without Normalization"
"ShakeShake-2x64d + SWA","ShakeShake-2x64d + SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"WRN-28-10 + SWA","WRN-28-10 + SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"Deep pyramidal residual network","Deep pyramidal residual network","Deep Pyramidal Residual Networks"
"CoPaNet-R-164","CoPaNet-R-164","Deep Competitive Pathway Networks"
"DenseNet","DenseNet","Densely Connected Convolutional Networks"
"Fractional MP","Fractional MP","Fractional Max-Pooling"
"Neural Architecture Search","Neural Architecture Search","Neural Architecture Search with Reinforcement Learning"
"SimpleNetv2","SimpleNetv2","Towards Principled Design of Deep Convolutional Networks: Introducing SimpNet"
"Wide ResNet","Wide ResNet","Wide Residual Networks"
"Evolution ensemble","Evolution ensemble","Large-Scale Evolution of Image Classifiers"
"ACN","ACN","Striving for Simplicity: The All Convolutional Net"
"SimpleNetv1","SimpleNetv1","Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures"
"ResNet-1001","ResNet-1001","Identity Mappings in Deep Residual Networks"
"Stochastic Depth","Stochastic Depth","Deep Networks with Stochastic Depth"
"RL+NT","RL+NT","Efficient Architecture Search by Network Transformation"
"Evolution","Evolution","Large-Scale Evolution of Image Classifiers"
"Deep Complex","Deep Complex","Deep Complex Networks"
"ResNet+ELU","ResNet+ELU","Deep Residual Networks with Exponential Linear Unit"
"Fitnet4-LSUV","Fitnet4-LSUV","All you need is a good init"
"Tree+Max-Avg pooling","Tree+Max-Avg pooling","Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
"SSCNN","SSCNN","Spatially-sparse convolutional neural networks"
"Tuned CNN","Tuned CNN","Scalable Bayesian Optimization Using Deep Neural Networks"
"ResNet","ResNet","Deep Residual Learning for Image Recognition"
"Exponential Linear Units","Exponential Linear Units","Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"
"BNM NiN","BNM NiN","Batch-normalized Maxout Network in Network"
"Universum Prescription","Universum Prescription","Universum Prescription: Regularization using Unlabeled Data"
"CMsC","CMsC","Competitive Multi-scale Convolution"
"RCNN-96","RCNN-96",""
"NiN+APL","NiN+APL","Learning Activation Functions to Improve Deep Neural Networks"
"cifar.torch","cifar.torch",""
"VDN","VDN","Training Very Deep Networks"
"SWWAE","SWWAE","Stacked What-Where Auto-encoders"
"MLR DNN","MLR DNN",""
"DSN","DSN","Deeply-Supervised Nets"
"BinaryConnect","BinaryConnect","BinaryConnect: Training Deep Neural Networks with binary weights during propagations"
"CLS-GAN","CLS-GAN","Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities"
"MIM","MIM","On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units"
"Spectral Representations for Convolutional Neural Networks","Spectral Representations for Convolutional Neural Networks","Spectral Representations for Convolutional Neural Networks"
"RMDL","RMDL","RMDL: Random Multimodel Deep Learning for Classification"
"NiN","NiN","Network In Network"
"ELC","ELC",""
"Deep Networks with Internal Selective Attention through Feedback Connections","Deep Networks with Internal Selective Attention through Feedback Connections","Deep Networks with Internal Selective Attention through Feedback Connections"
"DropConnect","DropConnect",""
"Maxout Network (k=2)","Maxout Network (k=2)","Maxout Networks"
"DNN+Probabilistic Maxout","DNN+Probabilistic Maxout","Improving Deep Neural Networks with Probabilistic Maxout Units"
"GP EI","GP EI","Practical Bayesian Optimization of Machine Learning Algorithms"
"APAC","APAC","APAC: Augmented PAttern Classification with Neural Networks"
"DCNN+GFE","DCNN+GFE","Deep Convolutional Neural Networks as Generic Feature Extractors"
"DCNN","DCNN","ImageNet Classification with Deep Convolutional Neural Networks"
"RReLU","RReLU","Empirical Evaluation of Rectified Activations in Convolutional Network"
"MCDNN","MCDNN","Multi-column Deep Neural Networks for Image Classification"
"ReNet","ReNet","ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks"
"An Analysis of Unsupervised Pre-training in Light of Recent Advances","An Analysis of Unsupervised Pre-training in Light of Recent Advances","An Analysis of Unsupervised Pre-training in Light of Recent Advances"
"Stochastic Pooling","Stochastic Pooling","Stochastic Pooling for Regularization of Deep Convolutional Neural Networks"
"Improving neural networks by preventing co-adaptation of feature detectors","Improving neural networks by preventing co-adaptation of feature detectors","Improving neural networks by preventing co-adaptation of feature detectors"
"Discriminative Learning of Sum-Product Networks","Discriminative Learning of Sum-Product Networks",""
"Nonnegativity Constraints ","Nonnegativity Constraints ",""
"Local Transformations","Local Transformations",""
"CKN","CKN","Convolutional Kernel Networks"
"Discriminative Unsupervised Feature Learning with Convolutional Neural Networks","Discriminative Unsupervised Feature Learning with Convolutional Neural Networks","Discriminative Unsupervised Feature Learning with Convolutional Neural Networks"
"Hierarchical Kernel Descriptors","Hierarchical Kernel Descriptors",""
"Smooth Pooling Regions","Smooth Pooling Regions",""
"Learning with Recursive Perceptual Representations","Learning with Recursive Perceptual Representations","Learning with Recursive Perceptual Representations"
"An Analysis of Single-Layer Networks in Unsupervised Feature Learning ","An Analysis of Single-Layer Networks in Unsupervised Feature Learning ",""
"PCANet","PCANet","PCANet: A Simple Deep Learning Baseline for Image Classification?"
"FLSCNN","FLSCNN","Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network"
"IncResNetV2 SE","IncResNetV2 SE","The iNaturalist Species Classification and Detection Dataset"
"CapsNet","CapsNet","Dynamic Routing Between Capsules"
"GPIPE","GPIPE","GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"
"SENet + ShakeEven + Cutout","SENet + ShakeEven + Cutout","Squeeze-and-Excitation Networks"
"PyramidNet-272 + SWA","PyramidNet-272 + SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"WRN+SWA","WRN+SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"NiN+Superclass+CDJ","NiN+Superclass+CDJ","Deep Convolutional Decision Jungle for Image Classification"
"HD-CNN","HD-CNN","HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition"
"Deep Representation Learning with Target Coding","Deep Representation Learning with Target Coding",""
"Tree Priors","Tree Priors","Discriminative Transfer Learning with Tree-based Priors"
"Stable and Efficient Representation Learning with Nonnegativity Constraints ","Stable and Efficient Representation Learning with Nonnegativity Constraints ",""
"Receptive Field Learning","Receptive Field Learning",""
"Cutout","Cutout","Improved Regularization of Convolutional Neural Networks with Cutout"
"CC-GAN²","CC-GAN²","Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks"
"Convolutional Clustering","Convolutional Clustering","Convolutional Clustering for Unsupervised Learning"
"Multi-Task Bayesian Optimization","Multi-Task Bayesian Optimization","Multi-Task Bayesian Optimization"
"C-SVDDNet","C-SVDDNet","Unsupervised Feature Learning with C-SVDDNet"
"DFF Committees","DFF Committees","Committees of deep feedforward networks trained with few data"
"RGB-D Based Object Recognition","RGB-D Based Object Recognition",""
"Simulated Fixations","Simulated Fixations",""
"No more meta-parameter tuning in unsupervised sparse feature learning","No more meta-parameter tuning in unsupervised sparse feature learning","No more meta-parameter tuning in unsupervised sparse feature learning"
"Receptive Fields","Receptive Fields",""
"Invariant Representations with Local Transformations","Invariant Representations with Local Transformations",""
"Pooling-Invariant","Pooling-Invariant",""
"Deep Learning of Invariant Features via Simulated Fixations in Video","Deep Learning of Invariant Features via Simulated Fixations in Video",""
"Large FC CRF","Large FC CRF",""
"Harmony Potentials","Harmony Potentials",""
"Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation","Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",""
"MPP","MPP",""
"FC CRF","FC CRF",""
"HCRF+CO","HCRF+CO",""
"Are Spatial and Global Constraints Really Necessary for Segmentation?","Are Spatial and Global Constraints Really Necessary for Segmentation?",""
"Kernelized SSVMCRF","Kernelized SSVMCRF",""
"PMG","PMG",""
"Auto-Context","Auto-Context",""
"STF","STF",""
"TextonBoost","TextonBoost",""
"PatchMatchGraph","PatchMatchGraph",""
"EraseReLU","EraseReLU","EraseReLU: A Simple Way to Ease the Training of Deep Convolution Neural Networks"
"Regularization of Neural Networks using DropConnect","Regularization of Neural Networks using DropConnect",""
"FractalNet","FractalNet","FractalNet: Ultra-Deep Neural Networks without Residuals"
"DCNN","DCNN","Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks"
"Network in Network","Network in Network","Network In Network"
"Maxout","Maxout","Maxout Networks"
"Convolutional neural networks applied to house numbers digit classification","Convolutional neural networks applied to house numbers digit classification",""
"AmoebaNet-A","AmoebaNet-A","Regularized Evolution for Image Classifier Architecture Search"
"NASNET-A(6)","NASNET-A(6)","Learning Transferable Architectures for Scalable Image Recognition"
"SENet","SENet","Squeeze-and-Excitation Networks"
"DPN-131","DPN-131","Dual Path Networks"
"PolyNet","PolyNet","PolyNet: A Pursuit of Structural Diversity in Very Deep Networks"
"ResNeXt-101","ResNeXt-101","Aggregated Residual Transformations for Deep Neural Networks"
"Inception ResNet V2","Inception ResNet V2","Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
"JFT-300M Finetuning","JFT-300M Finetuning","Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"
"Xception","Xception","Xception: Deep Learning with Depthwise Separable Convolutions"
"ResNet-152 + SWA","ResNet-152 + SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"Inception V3","Inception V3","Rethinking the Inception Architecture for Computer Vision"
"DenseNet-161 + SWA","DenseNet-161 + SWA","Averaging Weights Leads to Wider Optima and Better Generalization"
"Inception V2","Inception V2","Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
"ShuffleNet","ShuffleNet","ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
"MobileNet-224","MobileNet-224","MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
"Inception V1","Inception V1","Going Deeper with Convolutions"
"SE-ResNet152  WMW","SE-ResNet152  WMW",""
"Trimps-Soushen","Trimps-Soushen",""
"MSRA","MSRA",""
"VGG","VGG",""
"Clarifai","Clarifai",""
"AlexNet  SuperVision","AlexNet  SuperVision",""
"XRCE","XRCE",""
"NEC UIUC","NEC UIUC",""
"Random Erasing","Random Erasing","Random Erasing Data Augmentation"
"DBSNN","DBSNN",""
"Fitnet-LSUV-SVM","Fitnet-LSUV-SVM","All you need is a good init"
"Energy-Based Sparse Represenation","Energy-Based Sparse Represenation",""
"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis","Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis",""
"HOPE","HOPE","Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks"
"Maxout Networks","Maxout Networks","Maxout Networks"
"COSFIRE","COSFIRE",""
"The Best Multi-Stage Architecture","The Best Multi-Stage Architecture",""
"Deformation Models","Deformation Models",""
"Trainable feature extractor","Trainable feature extractor",""
"ISVM","ISVM",""
"Sparse Coding","Sparse Coding",""
"invariant feature hierarchies","invariant feature hierarchies",""
"Shape contexts","Shape contexts",""
"CNN+Gabor Filters","CNN+Gabor Filters",""
"On Optimization Methods for Deep Learning","On Optimization Methods for Deep Learning",""
"Deep Fried Convnets","Deep Fried Convnets","Deep Fried Convnets"
"Sparse Activity and Sparse Connectivity in Supervised Learning","Sparse Activity and Sparse Connectivity in Supervised Learning","Sparse Activity and Sparse Connectivity in Supervised Learning"
"Explaining and Harnessing Adversarial Examples","Explaining and Harnessing Adversarial Examples","Explaining and Harnessing Adversarial Examples"
"CDBN","CDBN",""
"Supervised Translation-Invariant Sparse Coding","Supervised Translation-Invariant Sparse Coding",""
"Large-Margin kNN","Large-Margin kNN",""
"Deep Boltzmann Machines","Deep Boltzmann Machines",""
"StrongNet","StrongNet",""
"DBN","DBN",""
"CNN","CNN",""
"Reducing the dimensionality of data with neural networks","Reducing the dimensionality of data with neural networks",""
"Deep learning via semi-supervised embedding","Deep learning via semi-supervised embedding",""
"Counterfactual Regression + WASS","Counterfactual Regression + WASS","Estimating individual treatment effect: generalization bounds and algorithms"
"TARNet","TARNet","Estimating individual treatment effect: generalization bounds and algorithms"
"OLS with separate regressors for each treatment ","OLS with separate regressors for each treatment ","Estimating individual treatment effect: generalization bounds and algorithms"
"BART","BART","Estimating individual treatment effect: generalization bounds and algorithms"
"Causal Forest","Causal Forest","Estimating individual treatment effect: generalization bounds and algorithms"
"Balancing Neural Network","Balancing Neural Network","Estimating individual treatment effect: generalization bounds and algorithms"
"k-NN","k-NN","Estimating individual treatment effect: generalization bounds and algorithms"
"Balancing Linear Regression","Balancing Linear Regression","Estimating individual treatment effect: generalization bounds and algorithms"
"OLS with treatments as a feature","OLS with treatments as a feature","Estimating individual treatment effect: generalization bounds and algorithms"
"Random Forest","Random Forest","Estimating individual treatment effect: generalization bounds and algorithms"
"DCRNN","DCRNN","Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting"
"MT-DNN","MT-DNN","Multi-Task Deep Neural Networks for Natural Language Understanding"
"DIIN","DIIN","Natural Language Inference over Interaction Space"
"Bi-CAS-LSTM","Bi-CAS-LSTM","Cell-aware Stacked LSTMs for Modeling Sentences"
"pt-DecAtt","pt-DecAtt","Neural Paraphrase Identification of Questions with Noisy Pretraining"
"BiMPM","BiMPM","Bilateral Multi-Perspective Matching for Natural Language Sentences"
"GenSen","GenSen","Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning"
"Linear FullPosterior-MR","Linear FullPosterior-MR","Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling"
"NeuralLinear FullPosterior-MR","NeuralLinear FullPosterior-MR","Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling"
"SwiDeN","SwiDeN","SwiDeN : Convolutional Neural Networks For Depiction Invariant Object Recognition"
"MVCNN-MultiRes","MVCNN-MultiRes","Volumetric and Multi-View CNNs for Object Classification on 3D Data"
"FPNN (4-FCs + NF)","FPNN (4-FCs + NF)","FPNN: Field Probing Neural Networks for 3D Data"
"Variational Shape Learner","Variational Shape Learner","Learning a Hierarchical Latent-Variable Model of 3D Shapes"
"Parsing R-CNN + ResNext101","Parsing R-CNN + ResNext101","Parsing R-CNN for Instance-Level Human Analysis"
"PGN + ResNet101","PGN + ResNet101","Instance-level Human Parsing via Part Grouping Network"
"BERTSUM","BERTSUM","Fine-tune BERT for Extractive Summarization"
"BERTSUM+Transformer","BERTSUM+Transformer","Fine-tune BERT for Extractive Summarization"
"Bottom-Up Sum","Bottom-Up Sum","Bottom-Up Abstractive Summarization"
"C2F + ALTERNATE","C2F + ALTERNATE","Coarse-to-Fine Attention Models for Document Summarization"
"GPT-2","GPT-2","Language Models are Unsupervised Multitask Learners"
"EndDec+WFE","EndDec+WFE","Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization"
"DRGD","DRGD","Deep Recurrent Generative Decoder for Abstractive Text Summarization"
"Seq2seq + selective + MTL + ERAM","Seq2seq + selective + MTL + ERAM","Ensure the Correctness of the Summary: Incorporate Entailment Knowledge into Abstractive Sentence Summarization"
"SEASS","SEASS","Selective Encoding for Abstractive Sentence Summarization"
"RAS-Elman","RAS-Elman","Abstractive Sentence Summarization with Attentive Recurrent Neural Networks"
"words-lvt5k-1sent","words-lvt5k-1sent","Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond"
"ABS+","ABS+",""
"ABS","ABS",""
"FTSum_g","FTSum_g","Faithful to the Original: Fact Aware Neural Abstractive Summarization"
"Re^3 Sum","Re^3 Sum","Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization"
"Seq2seq + E2T_cnn","Seq2seq + E2T_cnn","Entity Commonsense Representation for Neural Abstractive Summarization"
"CGU","CGU","Global Encoding for Abstractive Summarization"
"Pointer + Coverage + EntailmentGen + QuestionGen","Pointer + Coverage + EntailmentGen + QuestionGen","Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation"
"Struct+2Way+Word","Struct+2Way+Word","Structure-Infused Copy Mechanisms for Abstractive Summarization"
"RT-GENE 4 model ensemble","RT-GENE 4 model ensemble","RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments"
"RT-GENE 2 model ensemble","RT-GENE 2 model ensemble","RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments"
"RT-GENE single model","RT-GENE single model","RT-GENE: Real-Time Eye Gaze Estimation in Natural Environments"
"CapsGNN","CapsGNN","Capsule Graph Neural Network"
"PSCN","PSCN","Learning Convolutional Neural Networks for Graphs"
"AWE","AWE","Anonymous Walk Embeddings"
"GCAPS-CNN","GCAPS-CNN","Graph Capsule Convolutional Neural Networks"
"Regularized Deep Regressor","Regularized Deep Regressor","Regularizing Face Verification Nets For Pain Intensity Regression"
"CNN Large + fine-tune","CNN Large + fine-tune","Cloze-driven Pretraining of Self-attention Networks"
"Self-attentive encoder + ELMo","Self-attentive encoder + ELMo","Constituency Parsing with a Self-Attentive Encoder"
"Model combination","Model combination","Improving Neural Parsing by Disentangling Model Combination and Reranking Effects"
"LSTM Encoder-Decoder + LSTM-LM","LSTM Encoder-Decoder + LSTM-LM","Direct Output Connection for a High-Rank Language Model"
"LSTM Encoder-Decoder + LSTM-LM","LSTM Encoder-Decoder + LSTM-LM","An Empirical Study of Building a Strong Baseline for Constituency Parsing"
"In-order","In-order","In-Order Transition-based Constituent Parsing"
"Semi-supervised LSTM-LM","Semi-supervised LSTM-LM","Parsing as Language Modeling"
"Stack-only RNNG","Stack-only RNNG","What Do Recurrent Neural Network Grammars Learn About Syntax?"
"Transformer","Transformer","Attention Is All You Need"
"Semi-supervised LSTM","Semi-supervised LSTM","Grammar as a Foreign Language"
"Self-trained parser","Self-trained parser",""
"RNN Grammar","RNN Grammar","Recurrent Neural Network Grammars"
"Transition-based+improved aligner+ensemble","Transition-based+improved aligner+ensemble","An AMR Aligner Tuned by Transition-based Parser"
"Incremental joint model","Incremental joint model","AMR Parsing with an Incremental Joint Model"
"Transition-based transducer","Transition-based transducer",""
"Imitation learning ","Imitation learning ","Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing"
"Flair embeddings","Flair embeddings","Contextual String Embeddings for Sequence Labeling"
"JMT","JMT","A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks"
"Low supervision","Low supervision","Deep multi-task learning with low level tasks supervised at lower layers"
"Suzuki and Isozaki","Suzuki and Isozaki",""
"NCRF++","NCRF++","NCRF++: An Open-source Neural Sequence Labeling Toolkit"
"Clark et al.","Clark et al.","Semi-Supervised Sequence Modeling with Cross-View Training"
"Lewis et al.","Lewis et al.","LSTM CCG Parsing"
"Vaswani et al.","Vaswani et al.","Supertagging With LSTMs"
"Xu et al.","Xu et al.",""
"NLRN","NLRN","Non-Local Recurrent Network for Image Restoration"
"MWCNN","MWCNN","Multi-level Wavelet-CNN for Image Restoration"
"DnCNN","DnCNN","Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising"
"FFDNet","FFDNet","FFDNet: Toward a Fast and Flexible Solution for CNN based Image Denoising"
"Deep CNN Denoiser","Deep CNN Denoiser","Learning Deep CNN Denoiser Prior for Image Restoration"
"N3Net","N3Net","Neural Nearest Neighbors Networks"
"Residual Dense Network +","Residual Dense Network +","Residual Dense Network for Image Restoration"
"RED30","RED30","Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections"
"RDN+","RDN+","Residual Dense Network for Image Restoration"
"Multi-Loss ResNet50","Multi-Loss ResNet50","Fine-Grained Head Pose Estimation Without Keypoints"
"3DDFA","3DDFA","Face Alignment Across Large Poses: A 3D Solution"
"FAN (12 points)","FAN (12 points)","How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)"
"KEPLER","KEPLER","KEPLER: Keypoint and Pose Estimation of Unconstrained Faces by Learning Efficient H-CNN Regressors"
"RetinaNet+Augmented Autoencoders+ICP","RetinaNet+Augmented Autoencoders+ICP","Implicit 3D Orientation Learning for 6D Object Detection from RGB Images"
"DenseFusion","DenseFusion","DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion"
"PoseCNN + ICP","PoseCNN + ICP","PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes"
"PointFusion","PointFusion","PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation"
"PoseCNN + DeepIM","PoseCNN + DeepIM","DeepIM: Deep Iterative Matching for 6D Pose Estimation"
"Keypoint detector localization","Keypoint detector localization","Estimating 6D Pose From Localizing Designated Surface Keypoints"
"Single-shot deep CNN","Single-shot deep CNN","Real-Time Seamless Single Shot 6D Object Pose Prediction"
"BB8","BB8","BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth"
"PoseCNN","PoseCNN","PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes"
"SSD-6D","SSD-6D","SSD-6D: Making RGB-based 3D detection and 6D pose estimation great again"
"Fully-connected CRF + geometric check","Fully-connected CRF + geometric check","Global Hypothesis Generation for 6D Object Pose Estimation"
"Point Pair Features","Point Pair Features","Going Further with Point Pair Features"
"HRNet-48","HRNet-48","Deep High-Resolution Representation Learning for Human Pose Estimation"
"HRNet-32","HRNet-32","Deep High-Resolution Representation Learning for Human Pose Estimation"
"ResNet-50","ResNet-50","Simple Baselines for Human Pose Estimation and Tracking"
"Pose Residual Network","Pose Residual Network","MultiPoseNet: Fast Multi-Person Pose Estimation using Pose Residual Network"
"Mask R-CNN + NL blocks (4 in head, 1 in backbone)","Mask R-CNN + NL blocks (4 in head, 1 in backbone)","Non-local Neural Networks"
"Part Affinity Fields","Part Affinity Fields","Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields"
"ConvNet + deformable shape model","ConvNet + deformable shape model","6-DoF Object Pose from Semantic Keypoints"
"StarMap","StarMap","StarMap for Category-Agnostic Keypoint and Viewpoint Estimation"
"CNN + viewpoint estimates","CNN + viewpoint estimates","Viewpoints and Keypoints"
"ConvNet","ConvNet","Do Convnets Learn Correspondence?"
"V2V-PoseNet","V2V-PoseNet","V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation from a Single Depth Map"
"Pose Guidance","Pose Guidance","Pose Guided Structured Region Ensemble Network for Cascaded Hand Pose Estimation"
"Dense Pixel-wise Estimation","Dense Pixel-wise Estimation","Dense 3D Regression for Hand Pose Estimation"
"REN","REN","Region Ensemble Network: Improving Convolutional Network for Hand Pose Estimation"
"DeepPrior++","DeepPrior++","DeepPrior++: Improving Fast and Accurate 3D Hand Pose Estimation"
"DeeperCut","DeeperCut","DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model"
"DeepCut","DeepCut","DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation"
"Generative Partition Networks","Generative Partition Networks","Generative Partition Networks for Multi-Person Pose Estimation"
"Regional Multi-Person Pose Estimation","Regional Multi-Person Pose Estimation","RMPE: Regional Multi-person Pose Estimation"
"Associative Embedding","Associative Embedding","Associative Embedding: End-to-End Learning for Joint Detection and Grouping"
"Articulated Tracking","Articulated Tracking","ArtTrack: Articulated Multi-person Tracking in the Wild"
"Local Joint-to-Person Association","Local Joint-to-Person Association","Multi-Person Pose Estimation with Local Joint-to-Person Associations"
"ResNet","ResNet","An Integral Pose Regression System for the ECCV2018 PoseTrack Challenge"
"Fully supervised EpipolarPose","Fully supervised EpipolarPose","Self-Supervised Learning of 3D Human Pose using Multi-view Geometry"
"Self supervised EpipolarPose","Self supervised EpipolarPose","Self-Supervised Learning of 3D Human Pose using Multi-view Geometry"
"Neural Body Fitting (NBF)","Neural Body Fitting (NBF)","Neural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation"
"Weakly Supervised Transfer Learning","Weakly Supervised Transfer Learning","Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach"
"Sequence-to-sequence network ","Sequence-to-sequence network ","Exploiting temporal information for 3D pose estimation"
"Projected-pose belief maps + 2D fusion layers","Projected-pose belief maps + 2D fusion layers","Lifting from the Deep: Convolutional 3D Pose Estimation from a Single Image"
"DensePose + keypoints","DensePose + keypoints","DensePose: Dense Human Pose Estimation In The Wild"
"Stacked Hourglass Networks","Stacked Hourglass Networks","Stacked Hourglass Networks for Human Pose Estimation"
"Convolutional Pose Machines","Convolutional Pose Machines","Convolutional Pose Machines"
"Multi-task learning + viewpoint invariance","Multi-task learning + viewpoint invariance","Towards Viewpoint Invariant 3D Human Pose Estimation"
"Pyramid Residual Modules (PRMs)","Pyramid Residual Modules (PRMs)","Learning Feature Pyramids for Human Pose Estimation"
"Multi-Context Attention","Multi-Context Attention","Multi-Context Attention for Human Pose Estimation"
"DU-Net","DU-Net","Quantized Densely Connected U-Nets for Efficient Landmark Localization"
"Stacked hourglass + Inception-resnet","Stacked hourglass + Inception-resnet","Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation"
"Integral Regression","Integral Regression","Integral Human Pose Regression"
"CU-Net","CU-Net","CU-Net: Coupled U-Nets"
"ResNet-152 + intermediate supervision","ResNet-152 + intermediate supervision","DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model"
"Soft-argmax + contextual information","Soft-argmax + contextual information","Human Pose Regression by Combining Indirect Part Detection and Contextual Information"
"ResNet152","ResNet152","Simple Baselines for Human Pose Estimation and Tracking"
"MR-LSTM","MR-LSTM","A Mention-Ranking Model for Abstract Anaphora Resolution"
"MVD","MVD","Multi-View Silhouette and Depth Decomposition for High Resolution 3D Object Representation"
"Pixel2Mesh","Pixel2Mesh","Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images"
"PSG","PSG","A Point Set Generation Network for 3D Object Reconstruction from a Single Image"
"3D-R2N2","3D-R2N2","3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction"
"N3MR","N3MR","Neural 3D Mesh Renderer"
"DeepFlux","DeepFlux","DeepFlux for Skeletons in the Wild"
"Hi-Fi","Hi-Fi","Hi-Fi: Hierarchical Feature Integration for Skeleton Detection"
"FGFA + Seq-NMS","FGFA + Seq-NMS","Flow-Guided Feature Aggregation for Video Object Detection"
"Attention-based model","Attention-based model","Finding a Needle in the Haystack: Attention-Based Classification of High Resolution Microscopy Images"
"Sliding Window","Sliding Window","Detecting Cancer Metastases on Gigapixel Pathology Images"
"Recurrent Pixel Embedding","Recurrent Pixel Embedding","Recurrent Pixel Embedding for Instance Grouping"
"inst-DML","inst-DML","Semantic Instance Segmentation via Deep Metric Learning"
"PCL-OB-G-Ens + FRCNN","PCL-OB-G-Ens + FRCNN","PCL: Proposal Cluster Learning for Weakly Supervised Object Detection"
"OICR-Ens + FRCNN","OICR-Ens + FRCNN","Multiple Instance Detection Network with Online Instance Classifier Refinement"
"Deep Self-Taught Learning","Deep Self-Taught Learning","Deep Self-Taught Learning for Weakly Supervised Object Localization"
"WCCN","WCCN","Weakly Supervised Cascaded Convolutional Networks"
"MSLPD","MSLPD","Few-Example Object Detection with Model Communication"
"WSDDN + context","WSDDN + context","ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization"
"pipeline method","pipeline method","Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning"
"WSDDN-Ens","WSDDN-Ens","Weakly Supervised Deep Detection Networks"
"Self-paced curriculum learning","Self-paced curriculum learning","Bridging Saliency Detection to Weakly Supervised Object Detection Based on Self-paced Curriculum Learning"
"Online Instance Classifier Refinement","Online Instance Classifier Refinement","Multiple Instance Detection Network with Online Instance Classifier Refinement"
"SPNs","SPNs","Soft Proposal Networks for Weakly Supervised Object Localization"
"Deep Feature Maps","Deep Feature Maps","Weakly Supervised Localization using Deep Feature Maps"
"ProNet","ProNet","ProNet: Learning to Propose Object-specific Boxes for Cascaded Neural Networks"
"PointRCNN","PointRCNN","PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud"
"AVOD + Feature Pyramid","AVOD + Feature Pyramid","Joint 3D Proposal Generation and Object Detection from View Aggregation"
"IPOD","IPOD","IPOD: Intensive Point-based Object Detector for Point Cloud"
"PC-CNN-V2","PC-CNN-V2","A General Pipeline for 3D Detection of Vehicles"
"Frustum PointNets","Frustum PointNets","Frustum PointNets for 3D Object Detection from RGB-D Data"
"RoarNet","RoarNet","RoarNet: A Robust 3D Object Detection based on RegiOn Approximation Refinement"
"VoxelNet ","VoxelNet ","VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"
"VoxelNet","VoxelNet","VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"
"YOLOv3-tiny","YOLOv3-tiny","YOLOv3: An Incremental Improvement"
"YOLOv2 608x608","YOLOv2 608x608","YOLO9000: Better, Faster, Stronger"
"YOLOv3-416","YOLOv3-416","YOLOv3: An Incremental Improvement"
"YOLO","YOLO","You Only Look Once: Unified, Real-Time Object Detection"
"BlitzNet512 (s4)","BlitzNet512 (s4)","BlitzNet: A Real-Time Deep Network for Scene Understanding"
"BlitzNet512 (s8)","BlitzNet512 (s8)","BlitzNet: A Real-Time Deep Network for Scene Understanding"
"R-FCN","R-FCN","R-FCN: Object Detection via Region-based Fully Convolutional Networks"
"Faster R-CNN","Faster R-CNN","Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
"SNIPER","SNIPER","SNIPER: Efficient Multi-Scale Training"
"PANet + ResNeXt-101","PANet + ResNeXt-101","Path Aggregation Network for Instance Segmentation"
"D-RFCN + SNIP","D-RFCN + SNIP","DSOD: Learning Deeply Supervised Object Detectors from Scratch"
"M2Det","M2Det","M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network"
"ExtremeNet (MS)","ExtremeNet (MS)","Bottom-up Object Detection by Grouping Extreme and Center Points"
"Cascade R-CNN","Cascade R-CNN","Cascade R-CNN: Delving into High Quality Object Detection"
"RetinaMask + ResNeXt-101-FPN-GN ","RetinaMask + ResNeXt-101-FPN-GN ","RetinaMask: Learning to predict masks improves state-of-the-art single-shot detection for free"
"ResNet-101 + Group Normalization","ResNet-101 + Group Normalization","Group Normalization"
"RefineDet512+","RefineDet512+","Single-Shot Refinement Neural Network for Object Detection"
"GHM-C + GHM-R","GHM-C + GHM-R","Gradient Harmonized Single-stage Detector"
"D-RFCN + ResNet-101 (6 scales)","D-RFCN + ResNet-101 (6 scales)","Deformable Convolutional Networks"
"RetinaNet","RetinaNet","Focal Loss for Dense Object Detection"
"IoU-Net","IoU-Net","Acquisition of Localization Confidence for Accurate Object Detection"
"ResNet-50-FPN Mask R-CNN + KL Loss + var voting + soft-NMS","ResNet-50-FPN Mask R-CNN + KL Loss + var voting + soft-NMS","Bounding Box Regression with Uncertainty for Accurate Object Detection"
"FPN (ResNet101 backbone)","FPN (ResNet101 backbone)","ChainerCV: a Library for Deep Learning in Computer Vision"
"Faster R-CNN + TDM","Faster R-CNN + TDM","Beyond Skip Connections: Top-Down Modulation for Object Detection"
"Faster R-CNN + FPN","Faster R-CNN + FPN","Feature Pyramid Networks for Object Detection"
"Faster R-CNN + box refinement + context + multi-scale testing","Faster R-CNN + box refinement + context + multi-scale testing","Deep Residual Learning for Image Recognition"
"Faster R-CNN","Faster R-CNN","Speedaccuracy trade-offs for modern convolutional object detectors"
"YOLOv3 + Darknet-53","YOLOv3 + Darknet-53","YOLOv3: An Incremental Improvement"
"YOLO v2 + Darknet-19","YOLO v2 + Darknet-19","YOLO9000: Better, Faster, Stronger"
"OverFeat","OverFeat","OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"
"CoupleNet","CoupleNet","CoupleNet: Coupling Global Structure with Local Parts for Object Detection"
"SPP (Overfeat-7)","SPP (Overfeat-7)","Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition"
"BlitzNet512 + seg (s8)","BlitzNet512 + seg (s8)","BlitzNet: A Real-Time Deep Network for Scene Understanding"
"OHEM","OHEM","Training Region-based Object Detectors with Online Hard Example Mining"
"YOLO v2","YOLO v2","YOLO9000: Better, Faster, Stronger"
"DeNet-101 (skip)","DeNet-101 (skip)","DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling"
"ResNet-101","ResNet-101","Deep Residual Learning for Image Recognition"
"I+ORE","I+ORE","Random Erasing Data Augmentation"
"FRCN","FRCN","A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection"
"VGG-16 + KL Loss + var voting + soft-NMS","VGG-16 + KL Loss + var voting + soft-NMS","Bounding Box Regression with Uncertainty for Accurate Object Detection"
"FRCN","FRCN","Fast R-CNN"
"subCNN","subCNN","Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection"
"PWC-Net","PWC-Net","Models Matter, So Does Training: An Empirical Study of CNNs for Optical Flow Estimation"
"LiteFlowNet","LiteFlowNet","LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation"
"Spynet","Spynet","Optical Flow Estimation using a Spatial Pyramid Network"
"deep joint entity disambiguation w neural attention","deep joint entity disambiguation w neural attention","Deep Joint Entity Disambiguation with Local Neural Attention"
"(Lee et al., 2017)+ELMo","(Lee et al., 2017)+ELMo","Higher-Order Coreference Resolution with Coarse-to-Fine Inference"
"(Lee et al., 2017)+ELMo","(Lee et al., 2017)+ELMo","Deep contextualized word representations"
"Lee et al.","Lee et al.","End-to-end Neural Coreference Resolution"
"SymmFCNet (Full)","SymmFCNet (Full)","Learning Symmetry Consistent Deep CNNs for Face Completion"
"I-CFN","I-CFN","Hybrid Recommender System based on Autoencoders"
"U-CFN","U-CFN","Hybrid Recommender System based on Autoencoders"
"GC-MC","GC-MC","Graph Convolutional Matrix Completion"
"Factorized Exchangeable Autoencoder","Factorized Exchangeable Autoencoder","Deep Models of Interactions Across Sets"
"sRGCNN","sRGCNN","Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks"
"DeepRec","DeepRec","Training Deep AutoEncoders for Collaborative Filtering"
"Factorization with dictionary learning","Factorization with dictionary learning","Dictionary Learning for Massive Matrix Factorization"
"Mult-VAE PR","Mult-VAE PR","Variational Autoencoders for Collaborative Filtering"
"Mult-DAE","Mult-DAE","Variational Autoencoders for Collaborative Filtering"
"Sparse FC","Sparse FC","Kernelized Synaptic Weight Matrices"
"CF-NADE","CF-NADE","A Neural Autoregressive Approach to Collaborative Filtering"
"I-AutoRec","I-AutoRec","AutoRec: Autoencoders Meet Collaborative Filtering"
"NNMF","NNMF","Neural Network Matrix Factorization"
"GC-MC + feat","GC-MC + feat","Graph Convolutional Matrix Completion"
"Self-Supervised Exchangeable Model","Self-Supervised Exchangeable Model","Deep Models of Interactions Across Sets"
"GMC","GMC","Matrix Completion on Graphs"
"PI-REC","PI-REC","PI-REC: Progressive Image Reconstruction Network With Edge and Color Domain"
"MultiCCA + CNN","MultiCCA + CNN","A Corpus for Multilingual Document Classification in Eight Languages"
"BiLSTM (UN)","BiLSTM (UN)","A Corpus for Multilingual Document Classification in Eight Languages"
"BiLSTM (Europarl)","BiLSTM (Europarl)","A Corpus for Multilingual Document Classification in Eight Languages"
"Text2Vis","Text2Vis","Picture It In Your Mind: Generating High Level Visual Representations From Textual Descriptions"
"Neural transition-based model","Neural transition-based model","A Neural Transition-based Model for Nested Mention Recognition"
"AmoebaNet-B + co","AmoebaNet-B + co","Regularized Evolution for Image Classifier Architecture Search"
"PathLevel EAS + co","PathLevel EAS + co","Path-Level Network Transformation for Efficient Architecture Search"
"NASNet-A + co","NASNet-A + co","Neural Architecture Search with Reinforcement Learning"
"DARTS + co","DARTS + co","Learning Efficient Convolutional Networks through Network Slimming"
"ENAS + co","ENAS + co","Efficient Neural Architecture Search via Parameter Sharing"
"IAFN","IAFN","Unsupervised Domain Adaptation: An Adaptive Feature Norm Approach"
"IAFN+ENT","IAFN+ENT","Unsupervised Domain Adaptation: An Adaptive Feature Norm Approach"
"AdaSent","AdaSent","Self-Adaptive Hierarchical Sentence Model"
"CNN+MCFA","CNN+MCFA","Translations as Additional Contexts for Sentence Classification"
"Byte mLSTM","Byte mLSTM","Learning to Generate Reviews and Discovering Sentiment"
"USE","USE","Universal Sentence Encoder"
"Capsule-B ","Capsule-B ","Investigating Capsule Networks with Dynamic Routing for Text Classification"
"Fast Dropout","Fast Dropout",""
"SWEM-concat","SWEM-concat","Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms"
"GRU-RNN-GLOVE","GRU-RNN-GLOVE","All-but-the-Top: Simple and Effective Postprocessing for Word Representations"
"DELF+FT+ATT+DIR+QE","DELF+FT+ATT+DIR+QE","Large-Scale Image Retrieval with Attentive Deep Local Features"
"DIR+QE*","DIR+QE*","Deep Image Retrieval: Learning global representations for image search"
"DELF+FT+ATT","DELF+FT+ATT","Large-Scale Image Retrieval with Attentive Deep Local Features"
"siaMAC+QE*","siaMAC+QE*","CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples"
"ABE-8-512","ABE-8-512","Attention-based Ensemble for Deep Metric Learning"
"Anserini BM25+RM3","Anserini BM25+RM3","The Neural Hype and Comparisons Against Weak Baselines"
"SNRM-PRF","SNRM-PRF","From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing"
"NPRF-DRMM","NPRF-DRMM","NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval"
"SNRM","SNRM","From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing"
"NPRF-KNRM","NPRF-KNRM","NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval"
"FNRM-RankProb_Embed","FNRM-RankProb_Embed","Neural Ranking Models with Weak Supervision"
"FNRM-Rank_Embed","FNRM-Rank_Embed","Neural Ranking Models with Weak Supervision"
"DRMM","DRMM","A Deep Relevance Matching Model for Ad-hoc Retrieval"
"POSIT-DRMM-MV","POSIT-DRMM-MV","Deep Relevance Ranking Using Enhanced Document-Query Interactions"
"PACRR","PACRR","Deep Relevance Ranking Using Enhanced Document-Query Interactions"
"QL","QL","From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing"
"KNRM","KNRM","NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc Information Retrieval"
"PSENet-1s","PSENet-1s","Shape Robust Text Detection with Progressive Scale Expansion Network"
"SLPR","SLPR","Sliding Line Point Regression for Shape Robust Scene Text Detection"
"CTD+TLOC","CTD+TLOC","Detecting Curve Text in the Wild: New Dataset and New Solution"
"EAST","EAST","EAST: An Efficient and Accurate Scene Text Detector"
"SegLink","SegLink","Detecting Oriented Text in Natural Images by Linking Segments"
"FOTS","FOTS","FOTS: Fast Oriented Text Spotting with a Unified Network"
"Corner localization + region segmentation","Corner localization + region segmentation","Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation"
"FTSN","FTSN","Fused Text Segmentation Networks for Multi-oriented Scene Text Detection"
"R2CNN","R2CNN","R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection"
"WordSup","WordSup","WordSup: Exploiting Word Annotations for Character based Text Detection"
"SSTD","SSTD","Single Shot Text Detector with Regional Attention"
"Corner Localization + Region Segmentation","Corner Localization + Region Segmentation","Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation"
"Bag-of-Words","Bag-of-Words","A Large Self-Annotated Corpus for Sarcasm"
"Bag-of-Bigrams","Bag-of-Bigrams","A Large Self-Annotated Corpus for Sarcasm"
"CASCADE","CASCADE","CASCADE: Contextual Sarcasm Detection in Online Discussion Forums"
"Structural-scaffolds","Structural-scaffolds","Structural Scaffolds for Citation Intent Classification in Scientific Publications"
"SciBERT","SciBERT","SciBERT: Pretrained Contextualized Embeddings for Scientific Text"
"BiLSTM-Attention + ELMo","BiLSTM-Attention + ELMo","Deep contextualized word representations"
"Feature-rich Random Forest","Feature-rich Random Forest","Measuring the Evolution of a Scientific Field through Citation Frames"
"BiLSTM-Attention","BiLSTM-Attention","Hierarchical Attention Networks for Document Classification"
"SVM","SVM","Purpose and Polarity of Citation: Towards NLP-based Bibliometrics"
"Structural-Scaffolds","Structural-Scaffolds","Structural Scaffolds for Citation Intent Classification in Scientific Publications"
"BiLSTM-Attention + ELMo","BiLSTM-Attention + ELMo",""
"Feature-Rich Random Forest","Feature-Rich Random Forest","Measuring the Evolution of a Scientific Field through Citation Frames"
"Transformer (finetune)","Transformer (finetune)","Practical Text Classification With Large Pre-Trained Language Models"
"BERT","BERT","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"BiLSTM-Attention","BiLSTM-Attention",""
"Hierarchical Neural Networks","Hierarchical Neural Networks","Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts"
"Random Forest","Random Forest","Measuring the Evolution of a Scientific Field through Citation Frames"
"HDLTex","HDLTex","HDLTex: Hierarchical Deep Learning for Text Classification"
"L MIXED","L MIXED","Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function"
"Rules","Rules","High Accuracy Rule-based Question Classification using Question Syntax and Semantics"
"SVM","SVM",""
"ULMFiT","ULMFiT","Universal Language Model Fine-tuning for Text Classification"
"DRNN","DRNN","Disconnected Recurrent Neural Networks for Text Categorization"
"CNN","CNN","Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings"
"DPCNN","DPCNN","Deep Pyramid Convolutional Neural Networks for Text Categorization"
"EXAM","EXAM","Explicit Interaction Model towards Text Classification"
"fastText","fastText","Bag of Tricks for Efficient Text Classification"
"LEAM","LEAM","Joint Embedding of Words and Labels for Text Classification"
"CCCapsNet","CCCapsNet","Compositional coding capsule network with k-means routing for text classification"
"Balanced+bi-leaf-RNN","Balanced+bi-leaf-RNN","On Tree-Based Neural Sentence Modeling"
"VDCN","VDCN","Very Deep Convolutional Networks for Text Classification"
"SVDCNN","SVDCNN","Squeezed Very Deep Convolutional Neural Networks for Text Classification"
"Char-level CNN","Char-level CNN","Character-level Convolutional Networks for Text Classification"
"Seq2CNN with GWS(50)","Seq2CNN with GWS(50)","Abstractive Text Classification Using Sequence-to-convolution Neural Networks"
"ToWE-SG","ToWE-SG","Task-oriented Word Embedding for Text Classification"
"USE_T+CNN","USE_T+CNN","Universal Sentence Encoder"
"LSTM-CNN","LSTM-CNN","Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling"
"TBCNN","TBCNN","Discriminative Neural Sentence Modeling by Tree-Based Convolution"
"CoVe","CoVe","Learned in Translation: Contextualized Word Vectors"
"C-LSTM","C-LSTM","A C-LSTM Neural Network for Text Classification"
"SWEM-aver","SWEM-aver","Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms"
"SGCN","SGCN","Simplifying Graph Convolutional Networks"
"Text GCN","Text GCN","Graph Convolutional Networks for Text Classification"
"CNN+Lowercased","CNN+Lowercased","On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis"
"FastText","FastText","Bag of Tricks for Efficient Text Classification"
"Seq2CNN(50)","Seq2CNN(50)","Abstractive Text Classification Using Sequence-to-convolution Neural Networks"
"M-ACNN","M-ACNN","Learning Context-Sensitive Convolutional Filters for Text Processing"
"RESIDE","RESIDE","RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information"
"PCNN+ATT","PCNN+ATT","Neural Relation Extraction with Selective Attention over Instances"
"MIML-RE","MIML-RE",""
"MultiR","MultiR",""
"Lattice","Lattice","Chinese NER Using Lattice LSTM"
"BiLSTM+CRF+adversarial+self-attention","BiLSTM+CRF+adversarial+self-attention","Adversarial Transfer Learning for Chinese Named Entity Recognition with Self-Attention Mechanism"
"Aguilar et al.","Aguilar et al.","Modeling Noisiness to Recognize Named Entities using Multitask Neural Networks on Social Media"
"SpinningBytes","SpinningBytes","Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets"
"BERT Large","BERT Large","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"CVT + Multi-Task","CVT + Multi-Task","Semi-Supervised Sequence Modeling with Cross-View Training"
"BERT Base","BERT Base","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"Neural-CRF+AE","Neural-CRF+AE","Evaluating the Utility of Hand-crafted Features in Sequence Labelling"
"BiLSTM-CRF+ELMo","BiLSTM-CRF+ELMo","Deep contextualized word representations"
"LD-Net","LD-Net","Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling"
"TagLM","TagLM","Semi-supervised sequence tagging with bidirectional language models"
"CRF + AutoEncoder","CRF + AutoEncoder","Evaluating the Utility of Hand-crafted Features in Sequence Labelling"
"S-LSTM","S-LSTM","Sentence-State LSTM for Text Representation"
"LSTM with dynamic skip","LSTM with dynamic skip","Long Short-Term Memory with Dynamic Skip Connections"
"HSCRF","HSCRF","Hybrid semi-Markov CRF for Neural Sequence Labeling"
"Yang et al.","Yang et al.","Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks"
"LM-LSTM-CRF","LM-LSTM-CRF","Empower Sequence Labeling with Task-Aware Neural Language Model"
"Ma and Hovy","Ma and Hovy","End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF"
"LSTM-CRF","LSTM-CRF","Neural Architectures for Named Entity Recognition"
"SWEM-CRF","SWEM-CRF","Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms"
"VSL-GG-Hier","VSL-GG-Hier","Variational Sequential Labelers for Semi-Supervised Learning"
"Bi-LSTM-CRF + Lexical Features","Bi-LSTM-CRF + Lexical Features","Robust Lexical Features for Improved Neural Network Named-Entity Recognition"
"BiLSTM-CRF","BiLSTM-CRF","Fast and Accurate Entity Recognition with Iterated Dilated Convolutions"
"Iterated Dilated CNN","Iterated Dilated CNN","Fast and Accurate Entity Recognition with Iterated Dilated Convolutions"
"Joint Model","Joint Model",""
"Averaged Perceptron","Averaged Perceptron",""
"SCIIE","SCIIE","Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction"
"CollaboNet","CollaboNet","CollaboNet: collaboration of deep neural networks for biomedical named entity recognition"
"MMMU-BA","MMMU-BA","Contextual Inter-modal Attention for Multi-modal Sentiment Analysis"
"bc-LSTM","bc-LSTM","Context-Dependent Sentiment Analysis in User-Generated Videos"
"MARN","MARN","Multi-attention Recurrent Network for Human Communication Comprehension"
"CHFusion","CHFusion","Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling"
"Liu et al.","Liu et al.","Recurrent Entity Networks with Delayed Memory Update for Targeted Aspect-Based Sentiment Analysis"
"Sentic LSTM + TA + SA","Sentic LSTM + TA + SA","Targeted Aspect-Based Sentiment Analysis via Embedding Commonsense Knowledge into an Attentive LSTM"
"LSTM-LOC","LSTM-LOC","SentiHood: Targeted Aspect Based Sentiment Analysis Dataset for Urban Neighbourhoods"
"HAPN","HAPN","Hierarchical Attention Based Position-Aware Network for Aspect-Level Sentiment Analysis"
"SA-LSTM-P","SA-LSTM-P","Learning Latent Opinions for Aspect-Level Sentiment Classification"
"MGAN","MGAN","Exploiting Coarse-to-Fine Task Transfer for Aspect-level Sentiment Classification"
"LCR-Rot","LCR-Rot","Left-Center-Right Separated Neural Network for Aspect-based Sentiment Analysis with Rotatory Attention"
"BBLSTM-SL","BBLSTM-SL","Aspect-Based Sentiment Analysis Using Bitmask Bidirectional Long Short Term Memory Networks"
"MGAN","MGAN","Multi-grained Attention Network for Aspect-Level Sentiment Classification"
"AOA","AOA","Aspect Level Sentiment Classification with Attention-over-Attention Neural Networks"
"PBAN","PBAN","A Position-aware Bidirectional Attention Network for Aspect-level Sentiment Analysis"
"BILSTM-ATT-G (TSSVAE)","BILSTM-ATT-G (TSSVAE)","Variational Semi-supervised Aspect-term Sentiment Analysis via Transformer"
"AEN","AEN","Attentional Encoder Network for Targeted Sentiment Classification"
"MemNet","MemNet","Aspect Level Sentiment Classification with Deep Memory Network"
"TNet","TNet","Transformation Networks for Target-Oriented Sentiment Classification"
"LSTM+SynATT+TarRep","LSTM+SynATT+TarRep","Effective Attention Modeling for Aspect-Level Sentiment Classification"
"RAM","RAM","Recurrent Attention Network on Memory for Aspect Sentiment Analysis"
"IARM","IARM","IARM: Inter-Aspect Relation Modeling with Memory Networks in Aspect-Based Sentiment Analysis"
"PF-CNN","PF-CNN","Parameterized Convolutional Neural Networks for Aspect Level Sentiment Classification"
"PRET+MULT","PRET+MULT","Exploiting Document Knowledge for Aspect-level Sentiment Classification"
"JCI (hops)","JCI (hops)","Target-Sensitive Memory Networks for Aspect Sentiment Classification"
"IAN","IAN","Interactive Attention Networks for Aspect-Level Sentiment Classification"
"GCAE","GCAE","Aspect Based Sentiment Analysis with Gated Convolutional Networks"
"ATAE-LSTM ","ATAE-LSTM ","Attention-based LSTM for Aspect-level Sentiment Classification"
"NP (hops) ","NP (hops) ","Target-Sensitive Memory Networks for Aspect Sentiment Classification"
"TD-LSTM","TD-LSTM","Effective LSTMs for Target-Dependent Sentiment Classification"
"EDD-LG (shared)","EDD-LG (shared)","Learning Semantic Sentence Embeddings using Sequential Pair-wise Discriminator"
"Suffix BiLSTM","Suffix BiLSTM","Improved Sentence Modeling using Suffix Bidirectional LSTM"
"BCN+ELMo","BCN+ELMo","Deep contextualized word representations"
"BCN+Char+CoVe","BCN+Char+CoVe","Learned in Translation: Contextualized Word Vectors"
"CNN-RNF-LSTM","CNN-RNF-LSTM","Convolutional Neural Networks with Recurrent Neural Filters"
"MEAN","MEAN","A Multi-sentiment-resource Enhanced Attention Network for Sentiment Classification"
"Bi-LSTM+2+5","Bi-LSTM+2+5","Leveraging Multi-grained Sentiment Lexicon Information for Neural Sequence Models"
"Epic","Epic","Less Grammar, More Features"
"RNN-Capsule","RNN-Capsule","Sentiment Analysis by Capsules"
"RNTN","RNTN","Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
"GRU-RNN-WORD2VEC","GRU-RNN-WORD2VEC","All-but-the-Top: Simple and Effective Postprocessing for Word Representations"
"Joined Model Multi-tasking","Joined Model Multi-tasking","Exploring Joint Neural Model for Sentence Level Discourse Parsing and Sentiment Analysis"
"GloVe+Emo2Vec","GloVe+Emo2Vec","Emo2Vec: Learning Generalized Emotion Representation by Multi-task Training"
"Emo2Vec","Emo2Vec","Emo2Vec: Learning Generalized Emotion Representation by Multi-task Training"
"BiLSTM generalized pooling","BiLSTM generalized pooling","Enhancing Sentence Embedding with Generalized Pooling"
"SWEM-hier","SWEM-hier","Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms"
"CNN Large","CNN Large","Cloze-driven Pretraining of Self-attention Networks"
"Block-sparse LSTM","Block-sparse LSTM","GPU Kernels for Block-Sparse Weights"
"bmLSTM","bmLSTM","Learning to Generate Reviews and Discovering Sentiment"
"CNN","CNN","On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis"
"Neural Semantic Encoder","Neural Semantic Encoder","Neural Semantic Encoders"
"BLSTM-2DCNN","BLSTM-2DCNN","Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling"
"Standard DR-AGG","Standard DR-AGG","Information Aggregation via Dynamic Routing for Sequence Encoding"
"USE_T+CNN (lrn w.e.) ","USE_T+CNN (lrn w.e.) ","Universal Sentence Encoder"
"Reverse DR-AGG","Reverse DR-AGG","Information Aggregation via Dynamic Routing for Sequence Encoding"
"DC-MCNN","DC-MCNN","A Helping Hand: Transfer Learning for Deep Sentiment Analysis"
"ToWE-CBOW","ToWE-CBOW","Task-oriented Word Embedding for Text Classification"
"LSTMs+CNNs ensemble with multiple conv. ops ","LSTMs+CNNs ensemble with multiple conv. ops ","BB_twtr at SemEval-2017 Task 4: Twitter Sentiment Analysis with CNNs and LSTMs"
"Deep Bi-LSTM+attention","Deep Bi-LSTM+attention","DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis"
"oh-LSTM","oh-LSTM","Supervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings"
"Virtual adversarial training","Virtual adversarial training","Adversarial Training Methods for Semi-Supervised Text Classification"
"seq2-bown-CNN","seq2-bown-CNN","Effective Use of Word Order for Text Categorization with Convolutional Neural Networks"
"CNN+LSTM","CNN+LSTM","On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis"
"USE_T+CNN ","USE_T+CNN ","Universal Sentence Encoder"
"USE_T+DAN (w2v w.e.) ","USE_T+DAN (w2v w.e.) ","Universal Sentence Encoder"
"SRNN","SRNN","Sliced Recurrent Neural Networks"
"Gumbel+bi-leaf-RNN","Gumbel+bi-leaf-RNN","On Tree-Based Neural Sentence Modeling"
"Distributional Correspondence Indexing","Distributional Correspondence Indexing","Revisiting Distributional Correspondence Indexing: A Python Reimplementation and New Experiments"
"Multi-task tri-training","Multi-task tri-training","Strong Baselines for Neural Semi-supervised Learning under Domain Shift"
"VFAE","VFAE","The Variational Fair Autoencoder"
"Asymmetric tri-training","Asymmetric tri-training","Asymmetric Tri-training for Unsupervised Domain Adaptation"
"DANN","DANN","Domain-Adversarial Training of Neural Networks"
"USE_T+CNN (w2v w.e.) ","USE_T+CNN (w2v w.e.) ","Universal Sentence Encoder"
"jPTDP","jPTDP","An improved neural network model for joint POS tagging and dependency parsing"
"Andor et al.","Andor et al.","Globally Normalized Transition-Based Neural Networks"
"Weiss et al.","Weiss et al.","Structured Training for Neural Network Transition-Based Parsing"
"Deep Biaffine","Deep Biaffine","Deep Biaffine Attention for Neural Dependency Parsing"
"Distilled neural FOG","Distilled neural FOG","Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser"
"BIST transition-based parser","BIST transition-based parser","Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations"
"Arc-hybrid","Arc-hybrid","Training with Exploration Improves a Greedy Stack-LSTM Parser"
"BIST graph-based parser","BIST graph-based parser","Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations"
"BiLSTM-CRF","BiLSTM-CRF","From POS tagging to dependency parsing for biomedical event extraction"
"BiLSTM-JOINT","BiLSTM-JOINT","Jointly Learning to Label Sentences and Tokens"
"Ann+PAT+MT","Ann+PAT+MT","Artificial Error Generation with Machine Translation and Syntactic Patterns"
"Bi-LSTM + LMcost","Bi-LSTM + LMcost","Semi-supervised Multitask Learning for Sequence Labeling"
"Bi-LSTM + err POS GR ","Bi-LSTM + err POS GR ","Auxiliary Objectives for Neural Error Detection Models"
"Bi-LSTM + charattn","Bi-LSTM + charattn","Attending to Characters in Neural Sequence Labeling Models"
"Bi-LSTM","Bi-LSTM","Compositional Sequence Labeling Models for Error Detection in Learner Writing"
"BiLSTM-JOINT (trained on FCE)","BiLSTM-JOINT (trained on FCE)","Jointly Learning to Label Sentences and Tokens"
"Bi-LSTM + POS (unrestricted data)","Bi-LSTM + POS (unrestricted data)","Auxiliary Objectives for Neural Error Detection Models"
"Bi-LSTM (unrestricted data)","Bi-LSTM (unrestricted data)","Compositional Sequence Labeling Models for Error Detection in Learner Writing"
"Bi-LSTM + POS (trained on FCE)","Bi-LSTM + POS (trained on FCE)","Auxiliary Objectives for Neural Error Detection Models"
"Bi-LSTM + LMcost (trained on FCE)","Bi-LSTM + LMcost (trained on FCE)","Semi-supervised Multitask Learning for Sequence Labeling"
"Bi-LSTM (trained on FCE)","Bi-LSTM (trained on FCE)","Compositional Sequence Labeling Models for Error Detection in Learner Writing"
"SMT + BiGRU","SMT + BiGRU","Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation"
"CNN Seq2Seq + Quality Estimation","CNN Seq2Seq + Quality Estimation","Neural Quality Estimation of Grammatical Error Correction"
"Transformer","Transformer","Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task"
"CNN Seq2Seq","CNN Seq2Seq","A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction"
"CNN Seq2Seq + Fluency Boost","CNN Seq2Seq + Fluency Boost","Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study"
"CNN Seq2Seq + Fluency Boost and inference","CNN Seq2Seq + Fluency Boost and inference","Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study"
"Exact Set Matching","Exact Set Matching","Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task"
"InferSent","InferSent","Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
"USE_T","USE_T","Universal Sentence Encoder"
"LISA + ELMo","LISA + ELMo","Linguistically-Informed Self-Attention for Semantic Role Labeling"
"He et al. 2018 + ELMo","He et al. 2018 + ELMo","Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"
"LISA","LISA","Linguistically-Informed Self-Attention for Semantic Role Labeling"
"He et al. 2018","He et al. 2018","Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"
"DeepSRL","DeepSRL","Deep Semantic Role Labeling: What Works and Whatâ<U+0080><U+0099>s Next"
"BiLSTM-Span (Ensemble)","BiLSTM-Span (Ensemble)","A Span Selection Model for Semantic Role Labeling"
"BiLSTM-Span","BiLSTM-Span","A Span Selection Model for Semantic Role Labeling"
"Li et al.","Li et al.","Dependency or Span, End-to-End Uniform Semantic Role Labeling"
"He et al.,","He et al.,","Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"
"(He et al., 2017) + ELMo","(He et al., 2017) + ELMo","Deep contextualized word representations"
"Tan et al.","Tan et al.","Deep Semantic Role Labeling with Self-Attention"
"He et al.","He et al.","Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling"
"He et al.","He et al.","Deep Semantic Role Labeling: What Works and Whatâ<U+0080><U+0099>s Next"
"MoNoise","MoNoise","MoNoise: Modeling Noise Using a Modular Normalization System"
"Syllable based","Syllable based",""
"unLOL","unLOL",""
"Joint POS + Norm in a Viterbi decoding","Joint POS + Norm in a Viterbi decoding",""
"DialogueRNN","DialogueRNN","DialogueRNN: An Attentive RNN for Emotion Detection in Conversations"
"ICON","ICON","ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection"
"CMN","CMN","Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos"
"SPG","SPG","Self-produced Guidance for Weakly-supervised Object Localization"
"VoxelNe","VoxelNe","VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection"
"3DMV","3DMV","3DMV: Joint 3D-Multi-View Prediction for 3D Semantic Scene Segmentation"
"PointNet++","PointNet++","PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"
"DeepLab-LargeFOV","DeepLab-LargeFOV","Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"
"SegNet","SegNet","SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation"
"FCN","FCN","Fully Convolutional Networks for Semantic Segmentation"
"PSPNet","PSPNet","Pyramid Scene Parsing Network"
"BiSeNet","BiSeNet","BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation"
"ICNet","ICNet","ICNet for Real-Time Semantic Segmentation on High-Resolution Images"
"Dilation10","Dilation10","Multi-Scale Context Aggregation by Dilated Convolutions"
"DeepLab","DeepLab","Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"
"SwiftNetRN-18","SwiftNetRN-18","In Defense of Pre-trained ImageNet Architectures for Real-time Semantic Segmentation of Road-driving Images"
"FRRN","FRRN","Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes"
"CRF-RNN","CRF-RNN","Conditional Random Fields as Recurrent Neural Networks"
"ENet","ENet","ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation"
"Dilated FCN-2s RGB","Dilated FCN-2s RGB","Efficient Yet Deep Convolutional Neural Networks for Semantic Segmentation"
"DeepLabv3+ (Xception-JFT)","DeepLabv3+ (Xception-JFT)","Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation"
"DeepLabv3-JFT","DeepLabv3-JFT","Rethinking Atrous Convolution for Semantic Image Segmentation"
"Smooth Network with Channel Attention Block","Smooth Network with Channel Attention Block","Learning a Discriminative Feature Network for Semantic Segmentation"
"EncNet","EncNet","Context Encoding for Semantic Segmentation"
"ResNet-38 MS COCO","ResNet-38 MS COCO","Wider or Deeper: Revisiting the ResNet Model for Visual Recognition"
"Multipath-RefineNet","Multipath-RefineNet","RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation"
"Large Kernel Matters","Large Kernel Matters","Large Kernel Matters -- Improve Semantic Segmentation by Global Convolutional Network"
"TuSimple","TuSimple","Understanding Convolution for Semantic Segmentation"
"DeepLab-CRF (ResNet-101)","DeepLab-CRF (ResNet-101)","DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"
"Deeplab-v2 with Lovasz-Softmax loss","Deeplab-v2 with Lovasz-Softmax loss","The Lovász-Softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks"
"ImageNet+JFT-300M Initialization","ImageNet+JFT-300M Initialization","Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"
"DeepLab-MSc-CRF-LargeFOV","DeepLab-MSc-CRF-LargeFOV","Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"
"ParseNet","ParseNet","ParseNet: Looking Wider to See Better"
"Dilated FCN-2s VGG19","Dilated FCN-2s VGG19","Efficient Yet Deep Convolutional Neural Networks for Semantic Segmentation"
"Dilated Convolutions","Dilated Convolutions","Multi-Scale Context Aggregation by Dilated Convolutions"
"EncNet + JPU","EncNet + JPU","FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation"
"RefineNet","RefineNet","RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation"
"DilatedNet","DilatedNet","Multi-Scale Context Aggregation by Dilated Convolutions"
"FC-DenseNet103","FC-DenseNet103","The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation"
"ReSeg","ReSeg","ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation"
"SGPN","SGPN","SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation"
"PointNet++","PointNet++","PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"
"Joint Pyramid Upsampling + EncNet","Joint Pyramid Upsampling + EncNet","FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation"
"DUpsampling","DUpsampling","Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation"
"DeepLabV2","DeepLabV2","DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"
"VeryDeep","VeryDeep","Bridging Category-level and Instance-level Semantic Image Segmentation"
"Piecewise","Piecewise","Efficient piecewise training of deep structured models for semantic segmentation"
"HO CRF","HO CRF","Higher Order Conditional Random Fields in Deep Neural Networks"
"BoxSup","BoxSup","BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation"
"ParseNet ","ParseNet ","ParseNet: Looking Wider to See Better"
"FCN-8s","FCN-8s","Fully Convolutional Networks for Semantic Segmentation"
"Mapillary","Mapillary","In-Place Activated BatchNorm for Memory-Optimized Training of DNNs"
"OCNet","OCNet","OCNet: Object Context Network for Scene Parsing"
"Dual Attention Network","Dual Attention Network","Dual Attention Network for Scene Segmentation"
"ResNet-38","ResNet-38","Wider or Deeper: Revisiting the ResNet Model for Visual Recognition"
"C-SGC","C-SGC","Simplifying Graph Convolutional Networks"
"C-GCN","C-GCN","Graph Convolution over Pruned Dependency Trees Improves Relation Extraction"
"PA-LSTM","PA-LSTM","Position-aware Attention and Supervised Data Improve Slot Filling"
"Catena","Catena","CATENA: CAusal and TEmporal relation extraction from NAtural language texts"
"CAEVO","CAEVO",""
"Ning et al.","Ning et al.","A Structured Learning Approach to Temporal Relation Extraction"
"ClearTK","ClearTK",""
"CASENet","CASENet","CASENet: Deep Category-Aware Semantic Edge Detection"
"Kochkina et al. 2017","Kochkina et al. 2017","Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM"
"Bahuleyan and Vechtomova 2017","Bahuleyan and Vechtomova 2017","UWaterloo at SemEval-2017 Task 8: Detecting Stance towards Rumours with Topic Independent Features"
"WaveNet (L+F)","WaveNet (L+F)","WaveNet: A Generative Model for Raw Audio"
"LSTM-RNN parametric","LSTM-RNN parametric","WaveNet: A Generative Model for Raw Audio"
"HMM-driven concatenative","HMM-driven concatenative","WaveNet: A Generative Model for Raw Audio"
"Tacotron 2","Tacotron 2","Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions"
"WaveNet (Linguistic) ","WaveNet (Linguistic) ","Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions"
"Tacotron","Tacotron","Tacotron: Towards End-to-End Speech Synthesis"
"V-Net + Dice-based loss","V-Net + Dice-based loss","V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
"Fully-connected CRF","Fully-connected CRF","Conditional Random Fields as Recurrent Neural Networks for 3D Medical Imaging Segmentation"
"U-Net","U-Net","U-Net: Convolutional Networks for Biomedical Image Segmentation"
"LiviaNet (SemiDenseNet)","LiviaNet (SemiDenseNet)","Deep CNN ensembles and suggestive annotations for infant brain MRI segmentation"
"R2U-Net","R2U-Net","Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation"
"Residual U-Net","Residual U-Net","Road Extraction by Deep Residual U-Net"
"Att U-Net","Att U-Net","Attention U-Net: Learning Where to Look for the Pancreas"
"Holistic-nested CNN","Holistic-nested CNN","Spatial Aggregation of Holistically-Nested Convolutional Neural Networks for Automated Pancreas Localization and Segmentation"
"Multi-class 3D FCN","Multi-class 3D FCN","An application of cascaded 3D fully convolutional networks for medical image segmentation"
"LadderNet","LadderNet","LadderNet: Multi-path networks based on U-Net for medical image segmentation"
"InputCascadeCNN","InputCascadeCNN","Brain Tumor Segmentation with Deep Neural Networks"
"CNN + 3D filters","CNN + 3D filters","CNN-based Segmentation of Medical Imaging Data"
"U-Net + more filters + data augmentation + dice-loss","U-Net + more filters + data augmentation + dice-loss","Brain Tumor Segmentation and Radiomics Survival Prediction: Contribution to the BRATS 2017 Challenge"
"AFN-6","AFN-6","Autofocus Layer for Semantic Segmentation"
"Multi-Scale 3D + FC-CRF","Multi-Scale 3D + FC-CRF","Efficient Multi-Scale 3D CNN with Fully Connected CRF for Accurate Brain Lesion Segmentation"
"Automatic skin lesion segmentation with fully convolutional-deconvolutional networks","Automatic skin lesion segmentation with fully convolutional-deconvolutional networks","Automatic skin lesion segmentation with fully convolutional-deconvolutional networks"
"Attn U-Net + Multi-Input + FTL","Attn U-Net + Multi-Input + FTL","A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation"
"U-Net + FTL","U-Net + FTL","A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation"
"Attn U-Net + DL","Attn U-Net + DL","A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation"
"HyperDenseNet","HyperDenseNet","HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation"
"GraphConv + dummy super node","GraphConv + dummy super node","Learning Graph-Level Representation for Drug Discovery"
"GraphConv","GraphConv","Convolutional Networks on Graphs for Learning Molecular Fingerprints"
"MPNNs","MPNNs","Neural Message Passing for Quantum Chemistry"
"Gated Graph Sequence NN","Gated Graph Sequence NN","Gated Graph Sequence Neural Networks"
"Molecular Graph Convolutions","Molecular Graph Convolutions","Molecular Graph Convolutions: Moving Beyond Fingerprints"
"SNN","SNN","Self-Normalizing Neural Networks"
"GraphConv + dummy super node + focal loss","GraphConv + dummy super node + focal loss","Learning Graph-Level Representation for Drug Discovery"
"FRAGE + AWD-LSTM-MoS + dynamic eval ","FRAGE + AWD-LSTM-MoS + dynamic eval ","FRAGE: Frequency-Agnostic Word Representation"
"AWD-LSTM-DOC x5","AWD-LSTM-DOC x5","Direct Output Connection for a High-Rank Language Model"
"Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.","Past Decode Reg. + AWD-LSTM-MoS + dyn. eval.","Improved Language Modeling by Decoding the Past"
"AWD-LSTM-MoS + dynamic eval","AWD-LSTM-MoS + dynamic eval","Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"
"AWD-LSTM + dynamic eval","AWD-LSTM + dynamic eval","Dynamic Evaluation of Neural Sequence Models"
"AWD-LSTM-DOC + Partial Shuffle","AWD-LSTM-DOC + Partial Shuffle","Partially Shuffling the Training Data to Improve Language Models"
"AWD-LSTM-DOC","AWD-LSTM-DOC","Direct Output Connection for a High-Rank Language Model"
"AWD-LSTM + continuous cache pointer","AWD-LSTM + continuous cache pointer","Regularizing and Optimizing LSTM Language Models"
"AWD-LSTM-MoS + Partial Shuffle","AWD-LSTM-MoS + Partial Shuffle","Partially Shuffling the Training Data to Improve Language Models"
"Trellis Network","Trellis Network","Trellis Networks for Sequence Modeling"
"AWD-LSTM-MoS","AWD-LSTM-MoS","Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"
"Transformer-XL","Transformer-XL","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"2-layer skip-LSTM + dropout tuning ","2-layer skip-LSTM + dropout tuning ","Pushing the bounds of dropout"
"Differentiable NAS","Differentiable NAS","DARTS: Differentiable Architecture Search"
"AWD-LSTM 3-layer with Fraternal dropout","AWD-LSTM 3-layer with Fraternal dropout","Fraternal Dropout"
"AWD-LSTM","AWD-LSTM","Regularizing and Optimizing LSTM Language Models"
"Efficient NAS","Efficient NAS","Efficient Neural Architecture Search via Parameter Sharing"
"NAS Cell","NAS Cell","Neural Architecture Search with Reinforcement Learning"
"Recurrent highway networks","Recurrent highway networks","Recurrent Highway Networks"
"Tied Variational LSTM + augmented loss","Tied Variational LSTM + augmented loss","Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"
"Transformer-XL - 24 layers","Transformer-XL - 24 layers","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"Transformer-XL - 18 layers","Transformer-XL - 18 layers","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"64-layer Transformer","64-layer Transformer","Character-Level Language Modeling with Deeper Self-Attention"
"Transformer-XL - 12 layers","Transformer-XL - 12 layers","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"12-layer Transformer","12-layer Transformer","Character-Level Language Modeling with Deeper Self-Attention"
"Large mLSTM","Large mLSTM","Multiplicative LSTM for sequence modelling"
"Large FS-LSTM-4","Large FS-LSTM-4","Fast-Slow Recurrent Neural Networks"
"LN HM-LSTM","LN HM-LSTM","Hierarchical Multiscale Recurrent Neural Networks"
"Hypernetworks","Hypernetworks","HyperNetworks"
"Transformer-XL Large","Transformer-XL Large","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"Transformer with tied adaptive embeddings","Transformer with tied adaptive embeddings","Adaptive Input Representations for Neural Language Modeling"
"Transformer-XL Standard","Transformer-XL Standard","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"LSTM + Hebbian + Cache + MbPA","LSTM + Hebbian + Cache + MbPA","Fast Parametric Learning with Activation Memorization"
"4-layer QRNN","4-layer QRNN","An Analysis of Neural Language Modeling at Multiple Scales"
"LSTM + Hebbian","LSTM + Hebbian","Fast Parametric Learning with Activation Memorization"
"LSTM","LSTM","Fast Parametric Learning with Activation Memorization"
"Gated CNN","Gated CNN","Language Modeling with Gated Convolutional Networks"
"Neural cache model","Neural cache model","Improving Neural Language Models with a Continuous Cache"
"Temporal CNN","Temporal CNN","Convolutional Sequence Modeling Revisited"
"LSTM","LSTM","Improving Neural Language Models with a Continuous Cache"
"Adaptive Input Very Large","Adaptive Input Very Large","Adaptive Input Representations for Neural Language Modeling"
"Transformer-XL Base","Transformer-XL Base","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"Adaptive Input Large","Adaptive Input Large","Adaptive Input Representations for Neural Language Modeling"
"Mesh Tensorflow","Mesh Tensorflow","Mesh-TensorFlow: Deep Learning for Supercomputers"
"DynamicConv","DynamicConv","Pay Less Attention with Lightweight and Dynamic Convolutions"
"High-Budget MoE","High-Budget MoE","Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
"LSTM-8192-1024 + CNN Input","LSTM-8192-1024 + CNN Input","Exploring the Limits of Language Modeling"
"LSTM-8192-1024","LSTM-8192-1024","Exploring the Limits of Language Modeling"
" GCNN-14 bottleneck"," GCNN-14 bottleneck","Language Modeling with Gated Convolutional Networks"
"Low-Budget MoE","Low-Budget MoE","Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
"BIG G-LSTM-2","BIG G-LSTM-2","Factorization tricks for LSTM networks"
"RNN-1024 + 9 Gram","RNN-1024 + 9 Gram","One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling"
"Sparse Non-Negative","Sparse Non-Negative","Skip-gram Language Modeling Using Sparse Non-negative Matrix Probability Estimation"
"3-layer AWD-LSTM","3-layer AWD-LSTM","An Analysis of Neural Language Modeling at Multiple Scales"
"6-layer QRNN","6-layer QRNN","An Analysis of Neural Language Modeling at Multiple Scales"
"FS-LSTM-4","FS-LSTM-4","Fast-Slow Recurrent Neural Networks"
"FS-LSTM-2","FS-LSTM-2","Fast-Slow Recurrent Neural Networks"
"NASCell","NASCell","Neural Architecture Search with Reinforcement Learning"
"2-layer Norm HyperLSTM","2-layer Norm HyperLSTM","HyperNetworks"
"64-layer Character Transformer Model","64-layer Character Transformer Model","Character-Level Language Modeling with Deeper Self-Attention"
"12-layer Character Transformer Model","12-layer Character Transformer Model","Character-Level Language Modeling with Deeper Self-Attention"
"mLSTM + dynamic eval","mLSTM + dynamic eval","Dynamic Evaluation of Neural Sequence Models"
"Large mLSTM +emb +WN +VD","Large mLSTM +emb +WN +VD","Multiplicative LSTM for sequence modelling"
"Large RHN","Large RHN","Recurrent Highway Networks"
"LayerNorm HM-LSTM","LayerNorm HM-LSTM","Hierarchical Multiscale Recurrent Neural Networks"
"Unregularised mLSTM","Unregularised mLSTM","Multiplicative LSTM for sequence modelling"
"24-layer Transformer-XL","24-layer Transformer-XL","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"18-layer Transformer-XL","18-layer Transformer-XL","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"12-layer Transformer-XL","12-layer Transformer-XL","Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
"FRAGE + AWD-LSTM-MoS + dynamic eval","FRAGE + AWD-LSTM-MoS + dynamic eval","FRAGE: Frequency-Agnostic Word Representation"
"MFS baseline","MFS baseline",""
"supWSD","supWSD",""
"ELMo","ELMo","Deep Contextualized Word Representations"
"context2vec","context2vec",""
"Bi-LSTM<sub>att+LEX+POS<sub>","Bi-LSTM<sub>att+LEX+POS<sub>","Neural Sequence Learning Models for Word Sense Disambiguation"
"Bi-LSTM<sub>att+LEX<sub>","Bi-LSTM<sub>att+LEX<sub>","Neural Sequence Learning Models for Word Sense Disambiguation"
"GAS","GAS","Incorporating Glosses into Neural Word Sense Disambiguation"
"GAS<sub>ext<sub>","GAS<sub>ext<sub>","Incorporating Glosses into Neural Word Sense Disambiguation"
"supWSD<sub>emb<sub>","supWSD<sub>emb<sub>",""
"SemCor+WNGT, vocabulary reduced, ensemble","SemCor+WNGT, vocabulary reduced, ensemble","Improving the Coverage and the Generalization Ability of Neural Word Sense Disambiguation through Hypernymy and Hyponymy Relationships"
"LSTM (T:SemCor)","LSTM (T:SemCor)","Semi-supervised Word Sense Disambiguation with Neural Models"
"LSTMLP (T:SemCor, U:OMSTI)","LSTMLP (T:SemCor, U:OMSTI)","Semi-supervised Word Sense Disambiguation with Neural Models"
"LSTMLP (T:SemCor, U:1K)","LSTMLP (T:SemCor, U:1K)","Semi-supervised Word Sense Disambiguation with Neural Models"
"LSTMLP (T:OMSTI, U:1K)","LSTMLP (T:OMSTI, U:1K)","Semi-supervised Word Sense Disambiguation with Neural Models"
"LSTM (T:OMSTI)","LSTM (T:OMSTI)","Semi-supervised Word Sense Disambiguation with Neural Models"
"GASext (Linear)","GASext (Linear)","Incorporating Glosses into Neural Word Sense Disambiguation"
"GASext (Concatenation)","GASext (Concatenation)","Incorporating Glosses into Neural Word Sense Disambiguation"
"GAS (Concatenation)","GAS (Concatenation)","Incorporating Glosses into Neural Word Sense Disambiguation"
"GAS (Linear)","GAS (Linear)","Incorporating Glosses into Neural Word Sense Disambiguation"
"WSD-TM","WSD-TM","Knowledge-based Word Sense Disambiguation using Topic Models"
"Babelfy","Babelfy",""
"WN 1st sense baseline","WN 1st sense baseline",""
"UKB<sub>ppr_w2w-nf<sub>","UKB<sub>ppr_w2w-nf<sub>",""
"UKB<sub>ppr_w2w<sub>","UKB<sub>ppr_w2w<sub>",""
"ESIM + ELMo","ESIM + ELMo","SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"
"ESIM + GloVe","ESIM + GloVe","SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"
"Word-LM-partial","Word-LM-partial","A Simple Method for Commonsense Reasoning"
"Char-LM-partial","Char-LM-partial","A Simple Method for Commonsense Reasoning"
"USSM + Supervised DeepNet + KB","USSM + Supervised DeepNet + KB",""
"BiRNN 100d","BiRNN 100d","Event2Mind: Commonsense Inference on Events, Intents, and Reactions"
"ConvNet","ConvNet","Event2Mind: Commonsense Inference on Events, Intents, and Reactions"
"Cascaded-MTL","Cascaded-MTL","CNN-based Cascaded Multi-task Learning of High-level Prior and Density Estimation for Crowd Counting"
"BiLSTM","BiLSTM","Can Syntax Help? Improving an LSTM-based Sentence Compression Model for New Domains"
"BiRNN + LM Evaluator","BiRNN + LM Evaluator","A Language Model based Evaluator for Sentence Compression"
"LSTM","LSTM",""
"CESI","CESI","CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side Information"
"Galárraga et al., 2014","Galárraga et al., 2014",""
"Field-gating Seq2seq + dual attention","Field-gating Seq2seq + dual attention","Table-to-text Generation by Structure-aware Seq2seq Learning"
"Field-gating Seq2seq + dual attention + beam search","Field-gating Seq2seq + dual attention + beam search","Table-to-text Generation by Structure-aware Seq2seq Learning"
"Table NLM","Table NLM","Neural Text Generation from Structured Data with Application to the Biography Domain"
"Neural Content Planning + conditional copy","Neural Content Planning + conditional copy","Data-to-Text Generation with Content Selection and Planning"
"Encoder-decoder + conditional copy","Encoder-decoder + conditional copy","Challenges in Data-to-Document Generation"
"GCN EC","GCN EC","Deep Graph Convolutional Encoders for Structured Data to Text Generation"
"GCN + feat","GCN + feat","Deep Graph Convolutional Encoders for Structured Data to Text Generation"
"MrRNN Act.-Ent.","MrRNN Act.-Ent.","Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation"
"LeakGAN","LeakGAN","Long Text Generation via Adversarial Training with Leaked Information"
"RankGAN","RankGAN","Adversarial Ranking for Language Generation"
"SeqGAN","SeqGAN","SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient"
"Aggressive VAE","Aggressive VAE","Lagging Inference Networks and Posterior Collapse in Variational Autoencoders"
"SA-VAE","SA-VAE","Semi-Amortized Variational Autoencoders"
"CNN-VAE","CNN-VAE","Improved Variational Autoencoders for Text Modeling using Dilated Convolutions"
"AEM+Attention","AEM+Attention","An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation"
"Graph2Seq","Graph2Seq","A Graph-to-Sequence Model for AMR-to-Text Generation"
"STWGAN-GP","STWGAN-GP","Generating Text through Adversarial Training using Skip-Thought Vectors"
"BiLSTM","BiLSTM","Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond"
"X-BiLSTM","X-BiLSTM","Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
"X-CBOW","X-CBOW","Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
"Finetuned Transformer LM","Finetuned Transformer LM",""
"Hierarchical BiLSTM Max Pooling","Hierarchical BiLSTM Max Pooling","Natural Language Inference with Hierarchical BiLSTM Max Pooling Architecture"
"CAFE","CAFE","Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
"aESIM","aESIM","Attention Boosted Sequential Inference Model"
"Multi-task BiLSTM + Attn","Multi-task BiLSTM + Attn","GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
"V-BiMPM","V-BiMPM","Grounded Textual Entailment"
"BiMPM","BiMPM","Grounded Textual Entailment"
"Densely-Connected Recurrent and Co-Attentive Network Ensemble","Densely-Connected Recurrent and Co-Attentive Network Ensemble","Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information"
"Fine-Tuned LM-Pretrained Transformer","Fine-Tuned LM-Pretrained Transformer","Improving Language Understanding by Generative Pre-Training"
"300D DMAN Ensemble","300D DMAN Ensemble","Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference"
"150D Multiway Attention Network Ensemble","150D Multiway Attention Network Ensemble","Multiway Attention Networks for Modeling Sentence Pairs"
"450D DR-BiLSTM Ensemble","450D DR-BiLSTM Ensemble","DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference"
"300D CAFE Ensemble","300D CAFE Ensemble","Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
"ESIM + ELMo Ensemble","ESIM + ELMo Ensemble","Deep contextualized word representations"
"KIM Ensemble","KIM Ensemble","Neural Natural Language Inference Models Enhanced with External Knowledge"
"SLRC","SLRC","I Know What You Want: Semantic Learning for Text Comprehension"
"Densely-Connected Recurrent and Co-Attentive Network","Densely-Connected Recurrent and Co-Attentive Network","Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information"
"448D Densely Interactive Inference Network (DIIN, code) Ensemble","448D Densely Interactive Inference Network (DIIN, code) Ensemble","Natural Language Inference over Interaction Space"
"300D DMAN","300D DMAN","Discourse Marker Augmented Network with Reinforcement Learning for Natural Language Inference"
"BiMPM Ensemble","BiMPM Ensemble","Bilateral Multi-Perspective Matching for Natural Language Sentences"
"ESIM + ELMo","ESIM + ELMo","Deep contextualized word representations"
"KIM","KIM","Neural Natural Language Inference Models Enhanced with External Knowledge"
"600D ESIM + 300D Syntactic TreeLSTM","600D ESIM + 300D Syntactic TreeLSTM","Enhanced LSTM for Natural Language Inference"
"450D DR-BiLSTM","450D DR-BiLSTM","DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference"
"Stochastic Answer Network","Stochastic Answer Network","Stochastic Answer Networks for Natural Language Inference"
"300D CAFE","300D CAFE","Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
"150D Multiway Attention Network","150D Multiway Attention Network","Multiway Attention Networks for Modeling Sentence Pairs"
"Biattentive Classification Network + CoVe + Char","Biattentive Classification Network + CoVe + Char","Learned in Translation: Contextualized Word Vectors"
"448D Densely Interactive Inference Network (DIIN, code)","448D Densely Interactive Inference Network (DIIN, code)","Natural Language Inference over Interaction Space"
"300D re-read LSTM","300D re-read LSTM",""
"2400D Multiple-Dynamic Self-Attention Model","2400D Multiple-Dynamic Self-Attention Model","Dynamic Self-Attention : Computing Attention over Words Dynamically for Sentence Embedding"
"300D Full tree matching NTI-SLSTM-LSTM w global attention","300D Full tree matching NTI-SLSTM-LSTM w global attention","Neural Tree Indexers for Text Understanding"
"300D 2-layer Bi-CAS-LSTM","300D 2-layer Bi-CAS-LSTM","Cell-aware Stacked LSTMs for Modeling Sentences"
"200D decomposable attention model with intra-sentence attention","200D decomposable attention model with intra-sentence attention","A Decomposable Attention Model for Natural Language Inference"
"600D Dynamic Self-Attention Model","600D Dynamic Self-Attention Model","Dynamic Self-Attention : Computing Attention over Words Dynamically for Sentence Embedding"
"CBS-1 + ESIM","CBS-1 + ESIM","Parameter Re-Initialization through Cyclical Batch Size Schedules"
"512D Dynamic Meta-Embeddings","512D Dynamic Meta-Embeddings","Dynamic Meta-Embeddings for Improved Sentence Representations"
"600D BiLSTM with generalized pooling","600D BiLSTM with generalized pooling","Enhancing Sentence Embedding with Generalized Pooling"
"600D Hierarchical BiLSTM with Max Pooling (HBMP, code)","600D Hierarchical BiLSTM with Max Pooling (HBMP, code)","Natural Language Inference with Hierarchical BiLSTM Max Pooling Architecture"
"Densely-Connected Recurrent and Co-Attentive Network (encoder)","Densely-Connected Recurrent and Co-Attentive Network (encoder)","Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information"
"300D Reinforced Self-Attention Network","300D Reinforced Self-Attention Network","Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling"
"Distance-based Self-Attention Network","Distance-based Self-Attention Network","Distance-based Self-Attention Network for Natural Language Inference"
"200D decomposable attention model","200D decomposable attention model","A Decomposable Attention Model for Natural Language Inference"
"450D LSTMN with deep attention fusion","450D LSTMN with deep attention fusion","Long Short-Term Memory-Networks for Machine Reading"
"300D mLSTM word-by-word attention model","300D mLSTM word-by-word attention model","Learning Natural Language Inference with LSTM"
"600D Gumbel TreeLSTM encoders","600D Gumbel TreeLSTM encoders","Learning to Compose Task-Specific Tree Structures"
"600D Residual stacked encoders","600D Residual stacked encoders","Shortcut-Stacked Sentence Encoders for Multi-Domain Inference"
"300D CAFE (no cross-sentence attention)","300D CAFE (no cross-sentence attention)","Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference"
"1200D REGMAPR (Base+Reg)","1200D REGMAPR (Base+Reg)",""
"300D Residual stacked encoders","300D Residual stacked encoders","Shortcut-Stacked Sentence Encoders for Multi-Domain Inference"
"300D LSTMN with deep attention fusion","300D LSTMN with deep attention fusion","Long Short-Term Memory-Networks for Machine Reading"
"300D Gumbel TreeLSTM encoders","300D Gumbel TreeLSTM encoders","Learning to Compose Task-Specific Tree Structures"
"300D Directional self-attention network encoders","300D Directional self-attention network encoders","DiSAN: Directional Self-Attention Network for RNNCNN-Free Language Understanding"
"600D (300+300) Deep Gated Attn. BiLSTM encoders","600D (300+300) Deep Gated Attn. BiLSTM encoders","Recurrent Neural Network-Based Sentence Encoder with Gated Attention for Natural Language Inference"
"300D MMA-NSE encoders with attention","300D MMA-NSE encoders with attention","Neural Semantic Encoders"
"50D stacked TC-LSTMs","50D stacked TC-LSTMs","Modelling Interaction of Sentence Pair with coupled-LSTMs"
"600D (300+300) BiLSTM encoders with intra-attention and symbolic preproc.","600D (300+300) BiLSTM encoders with intra-attention and symbolic preproc.","Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention"
"300D NSE encoders","300D NSE encoders","Neural Semantic Encoders"
"100D DF-LSTM","100D DF-LSTM","Deep Fusion LSTMs for Text Semantic Matching"
"4096D BiLSTM with max-pooling","4096D BiLSTM with max-pooling","Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
"600D (300+300) BiLSTM encoders with intra-attention","600D (300+300) BiLSTM encoders with intra-attention","Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention"
"100D LSTMs w word-by-word attention","100D LSTMs w word-by-word attention","Reasoning about Entailment with Neural Attention"
"300D NTI-SLSTM-LSTM encoders","300D NTI-SLSTM-LSTM encoders","Neural Tree Indexers for Text Understanding"
"600D (300+300) BiLSTM encoders","600D (300+300) BiLSTM encoders","Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention"
"300D SPINN-PI encoders","300D SPINN-PI encoders","A Fast Unified Model for Parsing and Sentence Understanding"
"300D Tree-based CNN encoders","300D Tree-based CNN encoders","Natural Language Inference by Tree-Based Convolution and Heuristic Matching"
"1024D GRU encoders w unsupervised skip-thoughts pre-training","1024D GRU encoders w unsupervised skip-thoughts pre-training","Order-Embeddings of Images and Language"
"300D LSTM encoders","300D LSTM encoders","A Fast Unified Model for Parsing and Sentence Understanding"
"+ Unigram and bigram features","+ Unigram and bigram features","A large annotated corpus for learning natural language inference"
"100D LSTM encoders","100D LSTM encoders","A large annotated corpus for learning natural language inference"
"Unlexicalized features","Unlexicalized features","A large annotated corpus for learning natural language inference"
"LSTM","LSTM","Predictive Business Process Monitoring with LSTM Neural Networks"
"Up-Down","Up-Down","Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"
"HDU-USYD-UNCC","HDU-USYD-UNCC","VQA: Visual Question Answering"
"DLAIT","DLAIT","VQA: Visual Question Answering"
"MCB","MCB","Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"
"d-LSTM+nI","d-LSTM+nI","Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"
"CMN","CMN","Modeling Relationships in Referential Expressions with Compositional Modular Networks"
"MCB+Att.","MCB+Att.","Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding"
"MCB 7 att.","MCB 7 att.","Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding"
"joint-loss","joint-loss","Training Recurrent Answering Units with Joint Loss Minimization for VQA"
"MRN","MRN","Multimodal Residual Learning for Visual QA"
"HQI+ResNet","HQI+ResNet","Hierarchical Question-Image Co-Attention for Visual Question Answering"
"FDA","FDA","A Focused Dynamic Attention Model for Visual Question Answering"
"LSTM Q+I","LSTM Q+I","VQA: Visual Question Answering"
"iBOWIMG baseline","iBOWIMG baseline","Simple Baseline for Visual Question Answering"
"Graph VQA","Graph VQA","Graph-Structured Representations for Visual Question Answering"
"Dualnet ensemble","Dualnet ensemble","VQA: Visual Question Answering"
"LSTM + global features","LSTM + global features","VQA: Visual Question Answering"
"LSTM blind","LSTM blind","VQA: Visual Question Answering"
"N2NMN","N2NMN","Learning to Reason: End-to-End Module Networks for Visual Question Answering"
"MRN + global features","MRN + global features","Multimodal Residual Learning for Visual QA"
"CNN-RNN","CNN-RNN","Image Captioning and Visual Question Answering Based on Attributes and External Knowledge"
"SAN","SAN","Stacked Attention Networks for Image Question Answering"
"SMem-VQA","SMem-VQA","Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering"
"Denoising QA","Denoising QA","Denoising Distantly Supervised Open-Domain Question Answering"
"DecaProp","DecaProp","Densely Connected Attention Propagation for Reading Comprehension"
"R^3","R^3",""
"GA","GA","Gated-Attention Readers for Text Comprehension"
"BiDAF","BiDAF","Bidirectional Attention Flow for Machine Comprehension"
"Bi-Attention + DCU-LSTM","Bi-Attention + DCU-LSTM","Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension"
"AMANDA","AMANDA","A Question-Focused Multi-Factor Attention Network for Question Answering"
"Focused Hierarchical RNN","Focused Hierarchical RNN","Focused Hierarchical RNNs for Conditional Sequence Processing"
"ASR","ASR","Text Understanding with the Attention Sum Reader Network"
"HyperQA","HyperQA","Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering"
"PWIN","PWIN","Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement"
"aNMM","aNMM","aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model"
"CNN","CNN","Deep Learning for Answer Sentence Selection"
"Gated-Attention Reader","Gated-Attention Reader","CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension"
"Stanford Attentive Reader","Stanford Attentive Reader","CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension"
"Memory Networks (ensemble)","Memory Networks (ensemble)","Large-scale Simple Question Answering with Memory Networks"
"BERT (ensemble)","BERT (ensemble)","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"nlnet (ensemble)","nlnet (ensemble)",""
"BERT (single model)","BERT (single model)","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"QANet (ensemble)","QANet (ensemble)",""
"r-net (ensemble)","r-net (ensemble)",""
"MARS (ensemble)","MARS (ensemble)",""
"nlnet (single model)","nlnet (single model)",""
"MARS (single model)","MARS (single model)",""
"Reinforced Mnemonic Reader + A2D (ensemble model)","Reinforced Mnemonic Reader + A2D (ensemble model)",""
"r-net+ (ensemble)","r-net+ (ensemble)",""
"Hybrid AoA Reader (ensemble)","Hybrid AoA Reader (ensemble)",""
"QANet (single)","QANet (single)",""
"SLQA+ (ensemble)","SLQA+ (ensemble)",""
"Reinforced Mnemonic Reader (ensemble model)","Reinforced Mnemonic Reader (ensemble model)","Reinforced Mnemonic Reader for Machine Reading Comprehension"
"QANet (single model)","QANet (single model)",""
"AttentionReader+ (ensemble)","AttentionReader+ (ensemble)",""
"MMIPN","MMIPN",""
"Reinforced Mnemonic Reader + A2D (single model)","Reinforced Mnemonic Reader + A2D (single model)",""
"KACTEIL-MRC(GF-Net+) (ensemble)","KACTEIL-MRC(GF-Net+) (ensemble)",""
"Reinforced Mnemonic Reader + A2D + DA (single model)","Reinforced Mnemonic Reader + A2D + DA (single model)",""
"r-net (single model)","r-net (single model)",""
"BiDAF + Self Attention + ELMo (ensemble)","BiDAF + Self Attention + ELMo (ensemble)","Deep contextualized word representations"
"AVIQA+ (ensemble)","AVIQA+ (ensemble)",""
"SLQA+","SLQA+",""
"{EAZI} (ensemble)","{EAZI} (ensemble)",""
"EAZI+ (ensemble)","EAZI+ (ensemble)",""
"DNET (ensemble)","DNET (ensemble)",""
"Hybrid AoA Reader (single model)","Hybrid AoA Reader (single model)",""
"BiDAF + Self Attention + ELMo + A2D (single model)","BiDAF + Self Attention + ELMo + A2D (single model)",""
"r-net+ (single model)","r-net+ (single model)",""
"MAMCN+ (single model)","MAMCN+ (single model)","A Multi-Stage Memory Augmented Neural Network for Machine Reading Comprehension"
"SAN (ensemble model)","SAN (ensemble model)","Stochastic Answer Networks for Machine Reading Comprehension"
"Reinforced Mnemonic Reader (single model)","Reinforced Mnemonic Reader (single model)","Reinforced Mnemonic Reader for Machine Reading Comprehension"
"SLQA+ (single model)","SLQA+ (single model)",""
"Interactive AoA Reader+ (ensemble)","Interactive AoA Reader+ (ensemble)",""
"MIR-MRC(F-Net) (single model)","MIR-MRC(F-Net) (single model)",""
"MDReader","MDReader",""
"FusionNet (ensemble)","FusionNet (ensemble)","FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension"
"DCN+ (ensemble)","DCN+ (ensemble)","DCN+: Mixed Objective and Deep Residual Coattention for Question Answering"
"KACTEIL-MRC(GF-Net+) (single model)","KACTEIL-MRC(GF-Net+) (single model)",""
"BiDAF + Self Attention + ELMo (single model)","BiDAF + Self Attention + ELMo (single model)","Deep contextualized word representations"
"aviqa (ensemble)","aviqa (ensemble)",""
"Conductor-net (ensemble)","Conductor-net (ensemble)","Phase Conductor on Multi-layered Attentions for Machine Comprehension"
"KakaoNet (single model)","KakaoNet (single model)",""
"SLQA(ensemble)","SLQA(ensemble)",""
"MEMEN  (single model)","MEMEN  (single model)","MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension"
"BiDAF++ with pair2vec (single model)","BiDAF++ with pair2vec (single model)",""
"MDReader0","MDReader0",""
"test","test",""
"Interactive AoA Reader (ensemble)","Interactive AoA Reader (ensemble)",""
"DNET (single model)","DNET (single model)",""
"RaSoR + TR + LM (single model)","RaSoR + TR + LM (single model)","Contextualized Word Representations for Reading Comprehension"
"BiDAF++ (single model)","BiDAF++ (single model)",""
"AttentionReader+ (single)","AttentionReader+ (single)",""
"Jenga (ensemble)","Jenga (ensemble)",""
"{gqa} (single model)","{gqa} (single model)",""
"SAN (single model)","SAN (single model)","Stochastic Answer Networks for Machine Reading Comprehension"
"VS^3-NET (single model)","VS^3-NET (single model)",""
"r-net (single model)","r-net (single model)","Gated Self-Matching Networks for Reading Comprehension and Question Answering"
"FRC (single model)","FRC (single model)",""
"QANet + data augmentation ×3","QANet + data augmentation ×3","QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension"
"Conductor-net (ensemble)","Conductor-net (ensemble)",""
"KAR (single model)","KAR (single model)","Exploring Machine Reading Comprehension with Explicit Knowledge"
"smarnet (ensemble)","smarnet (ensemble)",""
"FusionNet (single model)","FusionNet (single model)","FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension"
"AVIQA-v2 (single model)","AVIQA-v2 (single model)",""
"Interactive AoA Reader+ (single model)","Interactive AoA Reader+ (single model)",""
"RaSoR + TR (single model)","RaSoR + TR (single model)","Contextualized Word Representations for Reading Comprehension"
"MEMEN (ensemble)","MEMEN (ensemble)","MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension"
"Mixed model (ensemble)","Mixed model (ensemble)",""
"two-attention-self-attention (ensemble)","two-attention-self-attention (ensemble)",""
"DCN+ (single model)","DCN+ (single model)","DCN+: Mixed Objective and Deep Residual Coattention for Question Answering"
"ReasoNet (ensemble)","ReasoNet (ensemble)","ReasoNet: Learning to Stop Reading in Machine Comprehension"
"eeAttNet (single model)","eeAttNet (single model)",""
"SSR-BiDAF","SSR-BiDAF",""
"SLQA (single model)","SLQA (single model)",""
"Conductor-net (single model)","Conductor-net (single model)","Phase Conductor on Multi-layered Attentions for Machine Comprehension"
"Jenga (single model)","Jenga (single model)",""
"Mnemonic Reader (ensemble)","Mnemonic Reader (ensemble)","Reinforced Mnemonic Reader for Machine Reading Comprehension"
"S^3-Net (ensemble)","S^3-Net (ensemble)",""
"SEDT (ensemble model)","SEDT (ensemble model)","Structural Embedding of Syntactic Trees for Machine Comprehension"
"SSAE (ensemble)","SSAE (ensemble)",""
"Multi-Perspective Matching (ensemble)","Multi-Perspective Matching (ensemble)","Multi-Perspective Context Matching for Machine Comprehension"
"BiDAF (ensemble)","BiDAF (ensemble)","Bidirectional Attention Flow for Machine Comprehension"
"SEDT+BiDAF (ensemble)","SEDT+BiDAF (ensemble)","Structural Embedding of Syntactic Trees for Machine Comprehension"
"Interactive AoA Reader (single model)","Interactive AoA Reader (single model)",""
"Conductor-net (single)","Conductor-net (single)","Phase Conductor on Multi-layered Attentions for Machine Comprehension"
"jNet (ensemble)","jNet (ensemble)","Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering"
"T-gating (ensemble)","T-gating (ensemble)",""
"two-attention-self-attention (single model)","two-attention-self-attention (single model)",""
"Conductor-net (single)","Conductor-net (single)",""
"AVIQA (single model)","AVIQA (single model)",""
"BiDAF + Self Attention (single model)","BiDAF + Self Attention (single model)","Simple and Effective Multi-Paragraph Reading Comprehension"
"S^3-Net (single model)","S^3-Net (single model)",""
"QFASE","QFASE",""
"attention+self-attention (single model)","attention+self-attention (single model)",""
"Dynamic Coattention Networks (ensemble)","Dynamic Coattention Networks (ensemble)","Dynamic Coattention Networks For Question Answering"
"smarnet (single model)","smarnet (single model)","Smarnet: Teaching Machines to Read and Comprehend Like Human"
"SRU","SRU","Simple Recurrent Units for Highly Parallelizable Recurrence"
"AttReader (single)","AttReader (single)",""
"DCN + Char + CoVe","DCN + Char + CoVe","Learned in Translation: Contextualized Word Vectors"
"M-NET (single)","M-NET (single)",""
"Mnemonic Reader (single model)","Mnemonic Reader (single model)","Reinforced Mnemonic Reader for Machine Reading Comprehension"
"MAMCN (single model)","MAMCN (single model)",""
"FastQAExt","FastQAExt","Making Neural QA as Simple as Possible but not Simpler"
"RaSoR (single model)","RaSoR (single model)","Learning Recurrent Span Representations for Extractive Question Answering"
"Document Reader (single model)","Document Reader (single model)","Reading Wikipedia to Answer Open-Domain Questions"
"Ruminating Reader (single model)","Ruminating Reader (single model)","Ruminating Reader: Reasoning with Gated Multi-Hop Attention"
"jNet (single model)","jNet (single model)","Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering"
"ReasoNet (single model)","ReasoNet (single model)","ReasoNet: Learning to Stop Reading in Machine Comprehension"
"Multi-Perspective Matching (single model)","Multi-Perspective Matching (single model)","Multi-Perspective Context Matching for Machine Comprehension"
"SimpleBaseline (single model)","SimpleBaseline (single model)",""
"SEDT+BiDAF (single model)","SEDT+BiDAF (single model)","Structural Embedding of Syntactic Trees for Machine Comprehension"
"FastQA","FastQA","Making Neural QA as Simple as Possible but not Simpler"
"PQMN (single model)","PQMN (single model)",""
"SEDT (single model)","SEDT (single model)","Structural Embedding of Syntactic Trees for Machine Comprehension"
"T-gating (single model)","T-gating (single model)",""
"BiDAF (single model)","BiDAF (single model)","Bidirectional Attention Flow for Machine Comprehension"
"Match-LSTM with Ans-Ptr (Boundary) (ensemble)","Match-LSTM with Ans-Ptr (Boundary) (ensemble)","Machine Comprehension Using Match-LSTM and Answer Pointer"
"FABIR","FABIR","A Fully Attention-Based Information Retriever"
"AllenNLP BiDAF (single model)","AllenNLP BiDAF (single model)",""
"Iterative Co-attention Network","Iterative Co-attention Network",""
"newtest","newtest",""
"Dynamic Coattention Networks (single model)","Dynamic Coattention Networks (single model)","Dynamic Coattention Networks For Question Answering"
"Match-LSTM with Bi-Ans-Ptr (Boundary)","Match-LSTM with Bi-Ans-Ptr (Boundary)","Machine Comprehension Using Match-LSTM and Answer Pointer"
"Unnamed submission by ravioncodalab","Unnamed submission by ravioncodalab",""
"OTF dict+spelling (single)","OTF dict+spelling (single)","Learning to Compute Word Embeddings On the Fly"
"Attentive CNN context with LSTM","Attentive CNN context with LSTM",""
"OTF spelling (single)","OTF spelling (single)","Learning to Compute Word Embeddings On the Fly"
"OTF spelling+lemma (single)","OTF spelling+lemma (single)","Learning to Compute Word Embeddings On the Fly"
"Dynamic Chunk Reader","Dynamic Chunk Reader","End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension"
"Fine-Grained Gating","Fine-Grained Gating","Words or Characters? Fine-grained Gating for Reading Comprehension"
"Match-LSTM with Ans-Ptr (Boundary)","Match-LSTM with Ans-Ptr (Boundary)","Machine Comprehension Using Match-LSTM and Answer Pointer"
"Match-LSTM with Ans-Ptr (Sentence)","Match-LSTM with Ans-Ptr (Sentence)","Machine Comprehension Using Match-LSTM and Answer Pointer"
"syntax, frame, coreference, and word embedding features","syntax, frame, coreference, and word embedding features","A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data"
"BERT-joint","BERT-joint","A BERT Baseline for the Natural Questions"
"CFC","CFC","Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering"
"Coref-GRU","Coref-GRU","Neural Models for Reasoning over Multiple Mentions using Coreference"
"MHPGM + NOIC","MHPGM + NOIC","Commonsense for Generative Multi-Hop Question Answering Tasks"
"BiDAF","BiDAF","Constructing Datasets for Multi-hop Reading Comprehension Across Documents"
"QRN","QRN","Query-Reduction Networks for Question Answering"
"EntNet","EntNet","Tracking the World State with Recurrent Entity Networks"
"DMN+","DMN+","Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes"
"End-To-End Memory Networks","End-To-End Memory Networks","End-To-End Memory Networks"
"RUM","RUM","Rotational Unit of Memory"
"GORU","GORU","Gated Orthogonal Recurrent Units: On Learning to Forget"
"LSTM","LSTM","Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes"
" RR"," RR","Recurrent Relational Networks"
"ReMO","ReMO","Finding ReMO (Related Memory Object): A Simple Neural Architecture for Text based Reasoning"
"SDNC","SDNC","Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes"
"ConvKN","ConvKN","ConvKN at SemEval-2016 Task 3: Answer and Question Selection for Question Answering on Arabic and English Fora"
"AP-CNN","AP-CNN","Attentive Pooling Networks"
"ARC-II","ARC-II","Convolutional Neural Network Architectures for Matching Natural Language Sentences"
"Kelp","Kelp","KeLP at SemEval-2016 Task 3: Learning Semantic Relations between Questions and Answers"
"Attentive LSTM","Attentive LSTM","Neural Variational Inference for Text Processing"
"LSTM (lexical overlap + dist output)","LSTM (lexical overlap + dist output)","Neural Variational Inference for Text Processing"
"Bigram-CNN (lexical overlap + dist output)","Bigram-CNN (lexical overlap + dist output)","Deep Learning for Answer Sentence Selection"
"Paragraph vector (lexical overlap + dist output)","Paragraph vector (lexical overlap + dist output)","Distributed Representations of Sentences and Documents"
"LSTM","LSTM","Neural Variational Inference for Text Processing"
"Bigram-CNN","Bigram-CNN","Deep Learning for Answer Sentence Selection"
"Paragraph vector","Paragraph vector","Distributed Representations of Sentences and Documents"
"BERT Large Augmented (single model)","BERT Large Augmented (single model)","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"SDNet (ensemble)","SDNet (ensemble)","SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering"
"BERT-base finetune (single model)","BERT-base finetune (single model)","BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
"SDNet (single model)","SDNet (single model)","SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering"
"FlowQA (single model)","FlowQA (single model)","FlowQA: Grasping Flow in History for Conversational Machine Comprehension"
"BiDAF++ (single model)","BiDAF++ (single model)","A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC"
"DrQA + seq2seq with copy attention (single model)","DrQA + seq2seq with copy attention (single model)","CoQA: A Conversational Question Answering Challenge"
"Vanilla DrQA (single model)","Vanilla DrQA (single model)","CoQA: A Conversational Question Answering Challenge"
"AP-BiLSTM","AP-BiLSTM","Attentive Pooling Networks"
"LSTM","LSTM","Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering"
"CNN","CNN","Hyperbolic Representation Learning for Fast and Efficient Neural Question Answering"
"Masque Q&A Style","Masque Q&A Style","Multi-style Generative Reading Comprehension"
"Deep Cascade QA","Deep Cascade QA","A Deep Cascade Model for Multi-Document Reading Comprehension"
"VNET","VNET","Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification"
"BiDaF Baseline","BiDaF Baseline","Bidirectional Attention Flow for Machine Comprehension"
"Parallel-Hierarchical","Parallel-Hierarchical","A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data"
"Memory chains and semantic supervision","Memory chains and semantic supervision","UNIMELB at SemEval-2016 Tasks 4A and 4B: An Ensemble of Neural Networks and a Word2Vec Based Model for Sentiment Classification"
"Hidden Coherence Model","Hidden Coherence Model","Story Comprehension for Predicting What Happens Next"
"val-LS-skip","val-LS-skip","A Simple and Effective Approach to the Story Cloze Test"
"Subgraph embeddings","Subgraph embeddings","Question Answering with Subgraph Embeddings"
"Weakly Supervised Embeddings","Weakly Supervised Embeddings","Open Question Answering with Weakly Supervised Embedding Models"
"BERT + Synthetic Self-Training (ensemble)","BERT + Synthetic Self-Training (ensemble)",""
"BERT finetune baseline (ensemble)","BERT finetune baseline (ensemble)",""
"Lunet + Verifier + BERT (ensemble)","Lunet + Verifier + BERT (ensemble)",""
"PAML+BERT (ensemble model)","PAML+BERT (ensemble model)",""
"Lunet + Verifier + BERT (single model)","Lunet + Verifier + BERT (single model)",""
"BERT + Synthetic Self-Training (single model)","BERT + Synthetic Self-Training (single model)",""
"PAML+BERT (single model)","PAML+BERT (single model)",""
"AoA + DA + BERT (ensemble)","AoA + DA + BERT (ensemble)",""
"BERT finetune baseline (single model)","BERT finetune baseline (single model)",""
"Candi-Net+BERT (ensemble)","Candi-Net+BERT (ensemble)",""
"AoA + DA + BERT (single model)","AoA + DA + BERT (single model)",""
"Candi-Net+BERT (single model)","Candi-Net+BERT (single model)",""
"Bert-raw (single model)","Bert-raw (single model)",""
"BERT + NeurQuRI (single model)","BERT + NeurQuRI (single model)",""
"PwP+BERT (single model)","PwP+BERT (single model)",""
"NEXYS_BASE (single model)","NEXYS_BASE (single model)",""
"L6Net + BERT (single model)","L6Net + BERT (single model)",""
"Bert-raw-full (single model)","Bert-raw-full (single model)",""
"BERT+AC(single model)","BERT+AC(single model)",""
"SLQA+BERT (single model)","SLQA+BERT (single model)",""
"synss (single model )","synss (single model )",""
"ARSG-BERT (single model)","ARSG-BERT (single model)",""
"{Anonymous} (single model)","{Anonymous} (single model)",""
"YARCS (ensemble)","YARCS (ensemble)",""
"RNANetSimple (ensemble)","RNANetSimple (ensemble)",""
"Reinforced Mnemonic Reader + Answer Verifier (single model)","Reinforced Mnemonic Reader + Answer Verifier (single model)","Read + Verify: Machine Reading Comprehension with Unanswerable Questions"
"BERT+Answer Verifier (single model)","BERT+Answer Verifier (single model)",""
"Unet (ensemble)","Unet (ensemble)","U-Net: Machine Reading Comprehension with Unanswerable Questions"
"RNANetSimple (single model)","RNANetSimple (single model)",""
"FusionNet++ (ensemble)","FusionNet++ (ensemble)","FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension"
"Multi-Level Attention Fusion(MLAF) (single model)","Multi-Level Attention Fusion(MLAF) (single model)",""
"Unet (single model)","Unet (single model)",""
"DocQA + NeurQuRI (single model)","DocQA + NeurQuRI (single model)",""
"ARRR (single model)","ARRR (single model)",""
"KACTEIL-MRC(GFN-Net) (single model)","KACTEIL-MRC(GFN-Net) (single model)",""
"EBB-Net (single model)","EBB-Net (single model)",""
"KakaoNet2 (single model)","KakaoNet2 (single model)",""
"abcNet (single model)","abcNet (single model)",""
"BSAE AddText (single model)","BSAE AddText (single model)",""
"BiDAF + Self Attention (single model)","BiDAF + Self Attention (single model)",""
"BiDAF-No-Answer (single model)","BiDAF-No-Answer (single model)",""
"Tree-LSTM + BiDAF + ELMo (single model)","Tree-LSTM + BiDAF + ELMo (single model)",""
"MemoReader","MemoReader","MemoReader: Large-Scale Reading Comprehension through Neural Memory Controller"
"S-Norm","S-Norm","Simple and Effective Multi-Paragraph Reading Comprehension"
"Reading Twice for NLU","Reading Twice for NLU","Dynamic Integration of Background Knowledge in Neural NLU Systems"
"Mnemonic Reader","Mnemonic Reader","Reinforced Mnemonic Reader for Machine Reading Comprehension"
"MEMEN","MEMEN","MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension"
"GA+MAGE (32)","GA+MAGE (32)","Linguistic Knowledge as Memory for Recurrent Neural Networks"
"GA Reader","GA Reader","Gated-Attention Readers for Text Comprehension"
"Attentive + relabling + ensemble","Attentive + relabling + ensemble","A Thorough Examination of the CNNDaily Mail Reading Comprehension Task"
"AIA","AIA","Iterative Alternating Neural Attention for Machine Reading"
"AS Reader (ensemble model)","AS Reader (ensemble model)","Text Understanding with the Attention Sum Reader Network"
"ReasoNet","ReasoNet","ReasoNet: Learning to Stop Reading in Machine Comprehension"
"AoA Reader","AoA Reader","Attention-over-Attention Neural Networks for Reading Comprehension"
"EpiReader","EpiReader","Natural Language Comprehension with the EpiReader"
"Dynamic Entity Repres. + w2v","Dynamic Entity Repres. + w2v","Dynamic Entity Representation with Max-pooling Improves Machine Reading"
"AttentiveReader + bilinear attention","AttentiveReader + bilinear attention","A Thorough Examination of the CNNDaily Mail Reading Comprehension Task"
"AS Reader (single model)","AS Reader (single model)","Text Understanding with the Attention Sum Reader Network"
"MemNNs (ensemble)","MemNNs (ensemble)","Teaching Machines to Read and Comprehend"
"Classifier","Classifier","A Thorough Examination of the CNNDaily Mail Reading Comprehension Task"
"Impatient Reader","Impatient Reader","Teaching Machines to Read and Comprehend"
"Attentive Reader","Attentive Reader","Teaching Machines to Read and Comprehend"
"IR Baseline","IR Baseline","Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification"
"Our Approach wo IR","Our Approach wo IR","Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification"
"IR++","IR++","Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification"
"OUR APPROACH","OUR APPROACH","Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification"
"WebQA","WebQA","Evaluating Semantic Parsing against a Simple Web-based Question Answering Model"
"NSE","NSE","Gated-Attention Readers for Text Comprehension"
"GA + feature + fix L(w)","GA + feature + fix L(w)","Gated-Attention Readers for Text Comprehension"
"AoA reader","AoA reader","Attention-over-Attention Neural Networks for Reading Comprehension"
"GA reader","GA reader","Gated-Attention Readers for Text Comprehension"
"AS reader (avg)","AS reader (avg)","Text Understanding with the Attention Sum Reader Network"
"AS reader (greedy)","AS reader (greedy)","Text Understanding with the Attention Sum Reader Network"
"ConZNet","ConZNet","Cut to the Chase: A Context Zoom-in Network for Reading Comprehension"
"BiAttention + DCU-LSTM","BiAttention + DCU-LSTM","Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension"
"PWIM","PWIM","Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement"
"Key-Value Memory Network","Key-Value Memory Network","Key-Value Memory Networks for Directly Reading Documents"
"LDC","LDC","Sentence Similarity Learning by Lexical Decomposition and Composition"
"PairwiseRank +  Multi-Perspective CNN","PairwiseRank +  Multi-Perspective CNN","Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency"
"MMA-NSE attention","MMA-NSE attention","Neural Semantic Encoders"
"BiAttention MRU","BiAttention MRU","Multi-range Reasoning for Machine Comprehension"
"MINIMAL(Dyn)","MINIMAL(Dyn)","Efficient and Robust Question Answering from Minimal Context over Documents"
"MultiObjectiveOptimization","MultiObjectiveOptimization","Multi-Task Learning as Multi-Objective Optimization"
"MGDA-UB","MGDA-UB","Multi-Task Learning as Multi-Objective Optimization"
"LFB NL","LFB NL","Long-Term Feature Banks for Detailed Video Understanding"
"NL I3D + GCN + Resnet-101","NL I3D + GCN + Resnet-101","Videos as Space-Time Region Graphs"
"CoViAR+optical flow","CoViAR+optical flow","Compressed Video Action Recognition"
"MultiScale TRN","MultiScale TRN","Temporal Relational Reasoning in Videos"
"ESPCN","ESPCN","Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network"
"SRCNN","SRCNN","Image Super-Resolution Using Deep Convolutional Networks"
"bicubic","bicubic","Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network"
"FRVSR","FRVSR","Frame-Recurrent Video Super-Resolution"
"SOF-VSR","SOF-VSR","Learning for Video Super-Resolution through HR Optical Flow Estimation"
"VESPCN","VESPCN","Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation"
"bicubic","bicubic","Real-Time Video Super-Resolution with Spatio-Temporal Networks and Motion Compensation"
"SiamMask","SiamMask","Fast Online Object Tracking and Segmentation: A Unifying Approach"
"Parameter-Free Spatial Attention","Parameter-Free Spatial Attention","Parameter-Free Spatial Attention Network for Person Re-Identification"
"MGN","MGN","Learning Discriminative Features with Multiple Granularities for Person Re-Identification"
"PCB (RPP)","PCB (RPP)","Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)"
"PCB (UP)","PCB (UP)","Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)"
"SVDNet + Random Erasing","SVDNet + Random Erasing","Random Erasing Data Augmentation"
"Incremental Learning","Incremental Learning","Incremental Learning in Person Re-Identification"
"IDE* + CamStyle + Random Erasing","IDE* + CamStyle + Random Erasing","Camera Style Adaptation for Person Re-identification"
"SVDNet","SVDNet","SVDNet for Pedestrian Retrieval"
"TriNet + Random Erasing","TriNet + Random Erasing","Random Erasing Data Augmentation"
"TriNet","TriNet","In Defense of the Triplet Loss for Person Re-Identification"
"IDE* + CamStyle","IDE* + CamStyle","Camera Style Adaptation for Person Re-identification"
"APR","APR","Improving Person Re-identification by Attribute and Identity Learning"
"IDE*","IDE*","Camera Style Adaptation for Person Re-identification"
"PAN","PAN","Pedestrian Alignment Network for Large-scale Person Re-identification"
"OIM","OIM","Joint Detection and Identification Feature Learning for Person Search"
"GAN","GAN","Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro"
"IDE","IDE","Person Re-identification: Past, Present and Future"
"LOMO + XQDA","LOMO + XQDA","Person Re-identification by Local Maximal Occurrence Representation and Metric Learning"
"BOW","BOW","Scalable Person Re-Identification: A Benchmark"
"PCB + RPP","PCB + RPP","Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)"
"PCB","PCB","Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)"
"GLAD*","GLAD*","GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval"
"PartLoss","PartLoss","Deep Representation Learning with Part Loss for Person Re-Identification"
"SSM","SSM","Scalable Person Re-identification on Supervised Smoothed Manifold"
"DJL","DJL","Person Re-Identification by Deep Joint Learning of Multi-Loss Classification"
"Re-rank","Re-rank","Re-ranking Person Re-identification with k-reciprocal Encoding"
"PDF","PDF","Pose-driven Deep Convolutional Model for Person Re-identification"
"DF","DF","Deeply-Learned Part-Aligned Representations for Person Re-Identification"
"DLCE","DLCE","A Discriminatively Learned CNN Embedding for Person Re-identification"
"MSCAN","MSCAN","Learning Deep Context-aware Features over Body and Latent Parts for Person Re-identification"
"DNS","DNS","Learning a Discriminative Null Space for Person Re-identification"
"StackGAN-v2","StackGAN-v2","StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks"
"StackGAN-v1 ","StackGAN-v1 ","StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks"
"AttnGAN","AttnGAN","AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks"
"AttnGAN + OP","AttnGAN + OP","Generating Multiple Objects at Spatially Distinct Locations"
"StackGAN + OP","StackGAN + OP","Generating Multiple Objects at Spatially Distinct Locations"
"GAWWN","GAWWN","Learning What and Where to Draw"
"AttnGAN+OP","AttnGAN+OP","Generating Images from Captions with Attention"
"StackGAN+OP","StackGAN+OP","Generating Images from Captions with Attention"
"BigGAN-deep","BigGAN-deep","Large Scale GAN Training for High Fidelity Natural Image Synthesis"
"BigGAN","BigGAN","Large Scale GAN Training for High Fidelity Natural Image Synthesis"
"Self-attention","Self-attention","Self-Attention Generative Adversarial Networks"
"Projection Discriminator","Projection Discriminator","cGANs with Projection Discriminator"
"AC-GAN","AC-GAN","Conditional Image Synthesis With Auxiliary Classifier GANs"
"Splitting GAN","Splitting GAN","Class-Splitting Generative Adversarial Networks"
"WGAN-GP","WGAN-GP","Improved Training of Wasserstein GANs"
"SGAN","SGAN","Stacked Generative Adversarial Networks"
"Improved GAN","Improved GAN","Improved Techniques for Training GANs"
"DCGAN","DCGAN","Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"
"SteinGAN","SteinGAN","Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning"
"MUNIT","MUNIT","Multimodal Unsupervised Image-to-Image Translation"
"UNIT","UNIT","Unsupervised Image-to-Image Translation Networks"
"CycleGAN","CycleGAN","Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"
"BicycleGAN","BicycleGAN","Toward Multimodal Image-to-Image Translation"
"Domain adaptation + ResNet-101","Domain adaptation + ResNet-101","Diverse Image-to-Image Translation via Disentangled Representations"
"Single-level Adaptation","Single-level Adaptation","Learning to Adapt Structured Output Space for Semantic Segmentation"
"CyCADA pixel+feat","CyCADA pixel+feat","CyCADA: Cycle-Consistent Adversarial Domain Adaptation"
"ROAD","ROAD","ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes"
"superpixel + color constancy","superpixel + color constancy","A Curriculum Domain Adaptation Approach to the Semantic Segmentation of Urban Scenes"
"CDA","CDA","Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes"
"FCNs in the wild","FCNs in the wild","FCNs in the Wild: Pixel-level Adversarial and Constraint-based Adaptation"
"DTN","DTN","Unsupervised Cross-Domain Image Generation"
"ADDA","ADDA","Adversarial Discriminative Domain Adaptation"
"DANN","DANN","Unsupervised Domain Adaptation by Backpropagation"
"CyCADA","CyCADA","CyCADA: Cycle-Consistent Adversarial Domain Adaptation"
"StarGAN","StarGAN","StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"
"DIA","DIA","Deep Identity-aware Transfer of Facial Attributes"
"IcGAN","IcGAN","Invertible Conditional GANs for image editing"
"cGAN","cGAN","Image-to-Image Translation with Conditional Adversarial Networks"
"DualGAN","DualGAN","DualGAN: Unsupervised Dual Learning for Image-to-Image Translation"
"pix2pix","pix2pix","Image-to-Image Translation with Conditional Adversarial Networks"
"CoGAN","CoGAN","Coupled Generative Adversarial Networks"
"SimGAN","SimGAN","Learning from Simulated and Unsupervised Images through Adversarial Training"
"BiGAN","BiGAN","Adversarially Learned Inference"
"SPADE","SPADE","Semantic Image Synthesis with Spatially-Adaptive Normalization"
"pix2pixHD","pix2pixHD","High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"
"CRN","CRN","Photographic Image Synthesis with Cascaded Refinement Networks"
"SIMS","SIMS","Semi-parametric Image Synthesis"
"PGGAN","PGGAN","Progressive Growing of GANs for Improved Quality, Stability, and Variation"
"MMD-GAN-rep","MMD-GAN-rep","Improving MMD-GAN Training with Repulsive Loss Function"
"SN-GANs","SN-GANs","Spectral Normalization for Generative Adversarial Networks"
"MSG-GAN","MSG-GAN","MSG-GAN: Multi-Scale Gradient GAN for Stable Image Synthesis"
"SN-SMMDGAN","SN-SMMDGAN","On gradient regularizers for MMD GANs"
"LR-GAN","LR-GAN","LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation"
"CEGAN-Ent-VI","CEGAN-Ent-VI","Calibrating Energy-based Generative Adversarial Networks"
"GMAN","GMAN","Generative Multi-Adversarial Networks"
"BEGAN","BEGAN","BEGAN: Boundary Equilibrium Generative Adversarial Networks"
"ALI","ALI","Adversarially Learned Inference"
"NICE","NICE","NICE: Non-linear Independent Components Estimation"
"DRAW","DRAW","DRAW: A Recurrent Neural Network For Image Generation"
"Real NVP","Real NVP","Density estimation using Real NVP"
"VAE with IAF","VAE with IAF","Improved Variational Inference with Inverse Autoregressive Flow"
"PixelRNN","PixelRNN","Density estimation using Real NVP"
"PixelCNN++","PixelCNN++",""
"Image Transformer","Image Transformer","Image Transformer"
"WGAN-GP + TT Update Rule","WGAN-GP + TT Update Rule","GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"
"RSGAN-GP","RSGAN-GP","The relativistic discriminator: a key element missing from standard GAN"
"FOGAN","FOGAN","First Order Generative Adversarial Networks"
"MSGAN","MSGAN","Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis"
"COCO-GAN","COCO-GAN","COCO-GAN: Generation by Parts via Conditional Coordinating"
"RaSGAN","RaSGAN","The relativistic discriminator: a key element missing from standard GAN"
"StyleGAN","StyleGAN","A Style-Based Generator Architecture for Generative Adversarial Networks"
"CRIM","CRIM","CRIM at SemEval-2018 Task 9: A Hybrid Approach to Hypernym Discovery"
"MFH","MFH",""
"300-sparsans","300-sparsans","300-sparsans at SemEval-2018 Task 9: Hypernymy as interaction of sparse attributes"
"vTE","vTE","Supervised Distributional Hypernym Discovery via Domain Adaptation"
"EXPR","EXPR","EXPR at SemEval-2018 Task 9: A Combined Approach for Hypernym Discovery"
"SJTU BCMI","SJTU BCMI","SJTU-NLP at SemEval-2018 Task 9: Neural Hypernym Discovery with Term Embeddings"
"ADAPT","ADAPT","ADAPT at SemEval-2018 Task 9: Skip-Gram Word Embeddings for Unsupervised Hypernym Discovery in Specialised Corpora"
"balAPInc","balAPInc","Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy Detection"
"NLP_HZ","NLP_HZ","NLP_HZ at SemEval-2018 Task 9: a Nearest Neighbor Approach"
"Apollo","Apollo","Apollo at SemEval-2018 Task 9: Detecting Hypernymy Relations Using Syntactic Dependencies"
"CRF-ASN","CRF-ASN","Dialogue Act Recognition via CRF-Attentive Structured Network"
"Bi-LSTM-CRF","Bi-LSTM-CRF","Dialogue Act Sequence Labeling using Hierarchical encoder with CRF"
"RNN with 3 utterances in context","RNN with 3 utterances in context","A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks"
"RNN","RNN",""
"Neural belief tracker","Neural belief tracker","Neural Belief Tracker: Data-Driven Dialogue State Tracking"
"Liu et al.","Liu et al.","Dialogue Learning with Human Teaching and Feedback in End-to-End Trainable Task-Oriented Dialogue Systems"
"Zhong et al.","Zhong et al.","Global-Locally Self-Attentive Dialogue State Tracker"
"GATE","GATE",""
"Adversarial Bi-LSTM","Adversarial Bi-LSTM","Robust Multilingual Part-of-Speech Tagging via Adversarial Training"
"Bi-LSTM","Bi-LSTM","Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss"
"Joint Bi-LSTM","Joint Bi-LSTM","A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing"
"Meta BiLSTM","Meta BiLSTM","Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings"
"Char Bi-LSTM","Char Bi-LSTM","Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"
"Feed Forward","Feed Forward","Supertagging With LSTMs"
"Bi-LSTM","Bi-LSTM","Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation"
"Deep Speech 2","Deep Speech 2","Deep Speech 2: End-to-End Speech Recognition in English and Mandarin"
"Deep Speech","Deep Speech","Deep Speech: Scaling up end-to-end speech recognition"
"HMM-TDNN(LFMMI) + LSTMLM + NN-GEV","HMM-TDNN(LFMMI) + LSTMLM + NN-GEV","Building state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline"
"CNN + Bi-RNN + CTC (speech to letters)","CNN + Bi-RNN + CTC (speech to letters)","Deep Speech: Scaling up end-to-end speech recognition"
"HMM-TDNN(LFMMI) + LSTMLM ","HMM-TDNN(LFMMI) + LSTMLM ","Building state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline"
"Li-GRU","Li-GRU","The PyTorch-Kaldi Speech Recognition Toolkit"
"tdnn + chain + rnnlm rescoring","tdnn + chain + rnnlm rescoring","Neural Network Language Modeling with Letter-based Features and Importance Sampling"
"TDNN + pNorm + speed updown speech","TDNN + pNorm + speed updown speech",""
"HMM-DNN + pNorm*","HMM-DNN + pNorm*",""
"Snips","Snips","Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces"
"HMM-(SAT)GMM","HMM-(SAT)GMM",""
"ResNet + BiLSTMs acoustic model","ResNet + BiLSTMs acoustic model","English Conversational Telephone Speech Recognition by Humans and Machines"
"Microsoft 2016b","Microsoft 2016b","Achieving Human Parity in Conversational Speech Recognition"
"Microsoft 2016","Microsoft 2016","The Microsoft 2016 Conversational Speech Recognition System"
"VGGResnetLACEBiLSTM acoustic model trained on SWB+Fisher+CH, N-gram + RNNLM language model trained on Switchboard+Fisher+Gigaword+Broadcast","VGGResnetLACEBiLSTM acoustic model trained on SWB+Fisher+CH, N-gram + RNNLM language model trained on Switchboard+Fisher+Gigaword+Broadcast","The Microsoft 2016 Conversational Speech Recognition System"
"RNN + VGG + LSTM acoustic model trained on SWB+Fisher+CH, N-gram + model M + NNLM language model","RNN + VGG + LSTM acoustic model trained on SWB+Fisher+CH, N-gram + model M + NNLM language model","The IBM 2016 English Conversational Telephone Speech Recognition System"
"CNN-LSTM","CNN-LSTM","Achieving Human Parity in Conversational Speech Recognition"
"IBM 2016","IBM 2016","The IBM 2016 English Conversational Telephone Speech Recognition System"
"RNNLM","RNNLM","The Microsoft 2016 Conversational Speech Recognition System"
"IBM 2015","IBM 2015","The IBM 2015 English Conversational Telephone Speech Recognition System"
"HMM-BLSTM trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher","HMM-BLSTM trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher",""
"HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher (10%  15.1% respectively trained on SWBD only)","HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations + Fisher (10%  15.1% respectively trained on SWBD only)",""
"CNN on MFSCfbanks + 1 non-conv layer for FMLLRI-Vectors concatenated in a DNN","CNN on MFSCfbanks + 1 non-conv layer for FMLLRI-Vectors concatenated in a DNN",""
"HMM-TDNN + iVectors","HMM-TDNN + iVectors",""
"Deep CNN (10 conv, 4 FC layers), multi-scale feature maps","Deep CNN (10 conv, 4 FC layers), multi-scale feature maps","Very Deep Multilingual Convolutional Neural Networks for LVCSR"
"HMM-DNN +sMBR","HMM-DNN +sMBR",""
"DNN sMBR","DNN sMBR",""
"Deep Speech + FSH","Deep Speech + FSH","Deep Speech: Scaling up end-to-end speech recognition"
"CNN + Bi-RNN + CTC (speech to letters), 25.9% WER if trainedonlyon SWB","CNN + Bi-RNN + CTC (speech to letters), 25.9% WER if trainedonlyon SWB","Deep Speech: Scaling up end-to-end speech recognition"
"DNN MMI","DNN MMI",""
"DNN MPE","DNN MPE",""
"DNN BMMI","DNN BMMI",""
"HMM-TDNN + pNorm + speed updown speech","HMM-TDNN + pNorm + speed updown speech",""
"DNN + Dropout","DNN + Dropout","Building DNN Acoustic Models for Large Vocabulary Speech Recognition"
"DNN","DNN","Building DNN Acoustic Models for Large Vocabulary Speech Recognition"
"CD-DNN","CD-DNN",""
"DNN-HMM","DNN-HMM",""
"LiGRU + Dropout + BatchNorm + Monophone Reg","LiGRU + Dropout + BatchNorm + Monophone Reg","The PyTorch-Kaldi Speech Recognition Toolkit"
"LSTM + Dropout + BatchNorm + Monophone Reg","LSTM + Dropout + BatchNorm + Monophone Reg","The PyTorch-Kaldi Speech Recognition Toolkit"
"Li-GRU + fMLLR features","Li-GRU + fMLLR features","Light Gated Recurrent Units for Speech Recognition"
"GRU + Dropout + BatchNorm + Monophone Reg","GRU + Dropout + BatchNorm + Monophone Reg","The PyTorch-Kaldi Speech Recognition Toolkit"
"RNN + Dropout + BatchNorm + Monophone Reg","RNN + Dropout + BatchNorm + Monophone Reg","The PyTorch-Kaldi Speech Recognition Toolkit"
"LSTM","LSTM","The PyTorch-Kaldi Speech Recognition Toolkit"
"Hierarchical maxout CNN + Dropout","Hierarchical maxout CNN + Dropout",""
"RNN","RNN","The PyTorch-Kaldi Speech Recognition Toolkit"
"GRU","GRU","The PyTorch-Kaldi Speech Recognition Toolkit"
"CNN in time and frequency + dropout, 17.6% wo dropout","CNN in time and frequency + dropout, 17.6% wo dropout",""
"Light Gated Recurrent Units","Light Gated Recurrent Units","Light Gated Recurrent Units for Speech Recognition"
"RNN-CRF on 24(x3) MFSC","RNN-CRF on 24(x3) MFSC","Segmental Recurrent Neural Networks for End-to-end Speech Recognition"
"Bi-RNN + Attention","Bi-RNN + Attention","Attention-Based Models for Speech Recognition"
"Bi-LSTM + skip connections w CTC","Bi-LSTM + skip connections w CTC","Speech Recognition with Deep Recurrent Neural Networks"
"QCNN-10L-256FM","QCNN-10L-256FM","Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition"
"Soft Monotonic Attention (ours, offline)","Soft Monotonic Attention (ours, offline)","Online and Linear-Time Attention by Enforcing Monotonic Alignments"
"(first, modern) HMM-DBN","(first, modern) HMM-DBN",""
"HMM-BLSTMtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD","HMM-BLSTMtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD",""
"HMM-TDNNtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD","HMM-TDNNtrained with MMI + data augmentation (speed) + iVectors + 3 regularizations + SWBD",""
"tdnn + chain","tdnn + chain","Purely sequence-trained neural networks for ASR based on lattice-free MMI"
"End-to-end LF-MMI","End-to-end LF-MMI","End-to-end speech recognition using lattice-free MMI"
"TC-DNN-BLSTM-DNN","TC-DNN-BLSTM-DNN","Deep Recurrent Neural Networks for Acoustic Modelling"
"test-set on open vocabulary (i.e. harder), model = HMM-DNN + pNorm*","test-set on open vocabulary (i.e. harder), model = HMM-DNN + pNorm*",""
"CNN over RAW speech (wav)","CNN over RAW speech (wav)",""
"VoiceFilter: bi-LSTM","VoiceFilter: bi-LSTM","VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking"
"Seq-to-seq attention","Seq-to-seq attention","Improved training of end-to-end attention models for speech recognition"
"HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations","HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations",""
"Gated ConvNets","Gated ConvNets","Letter-Based Speech Recognition with Gated ConvNets"
"CTC + policy learning","CTC + policy learning","Improving End-to-End Speech Recognition with Policy Learning"
"chain + tdnn + rnnlm rescoring, https:github.comkaldi-asrkaldiblobmasteregslibrispeechs5localrnnlmtuningrun_tdnn_lstm_1a.sh","chain + tdnn + rnnlm rescoring, https:github.comkaldi-asrkaldiblobmasteregslibrispeechs5localrnnlmtuningrun_tdnn_lstm_1a.sh","Neural Network Language Modeling with Letter-based Features and Importance Sampling"
"Residual net + Pseudo Sketch Feature Loss + LSGAN","Residual net + Pseudo Sketch Feature Loss + LSGAN","Semi-Supervised Learning for Face Sketch Synthesis in the Wild"
"PS2-MAN","PS2-MAN","High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks"
"HP-net","HP-net","HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis"
"MicronNet (fp16)","MicronNet (fp16)","MicronNet: A Highly Compact Deep Convolutional Neural Network Architecture for Real-time Embedded Traffic Sign Classification"
"Hierarchical + Background Threshold Model","Hierarchical + Background Threshold Model","A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection"
"Hierarchical Model","Hierarchical Model","A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection"
"Background Threshold Model","Background Threshold Model","A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection"
"VPGNet","VPGNet","VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition"
"Overfeat CNN detector + DBSCAN","Overfeat CNN detector + DBSCAN","An Empirical Evaluation of Deep Learning on Highway Driving"
"Spatial CNN","Spatial CNN","Spatial As Deep: Spatial CNN for Traffic Scene Understanding"
"Pairwise pixel supervision + FCN","Pairwise pixel supervision + FCN","Learning to Cluster for Proposal-Free Instance Segmentation"
"LaneNet","LaneNet","Towards End-to-End Lane Detection: an Instance Segmentation Approach"
"Discriminative loss function","Discriminative loss function","Semantic Instance Segmentation with a Discriminative Loss Function"
"SDS-RCNN","SDS-RCNN","Illuminating Pedestrians via Simultaneous Detection & Segmentation"
"F-DNN+SS","F-DNN+SS","Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection"
"SA-FastRCNN","SA-FastRCNN","Scale-aware Fast R-CNN for Pedestrian Detection"
"MS-CNN","MS-CNN","A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection"
"CompACT-Deep","CompACT-Deep","Learning Complexity-Aware Cascades for Deep Pedestrian Detection"
"Part-level CNN + saliency and bounding box alignment","Part-level CNN + saliency and bounding box alignment","Part-Level Convolutional Neural Networks for Pedestrian Detection Using Saliency and Boundary Box Alignment"
"Checkerboards+","Checkerboards+","Filtered Channel Features for Pedestrian Detection"
"TA-CNN","TA-CNN","Pedestrian Detection aided by Deep Learning Semantic Tasks"
"AlexNet","AlexNet","Taking a Deeper Look at Pedestrians"
"LDCF","LDCF","Local Decorrelation For Improved Pedestrian Detection"
"CNN features + Bayesian ridge regression","CNN features + Bayesian ridge regression","Transferring Rich Deep Features for Facial Beauty Prediction"
"Combined Features + Gaussian Reg","Combined Features + Gaussian Reg","SCUT-FBP5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction"
"Multi-View","Multi-View","Multi-View Dynamic Facial Action Unit Detection"
"Baseline","Baseline","FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge"
"GFA-CNN","GFA-CNN","Learning Generalizable and Identity-Discriminative Representations for Face Anti-Spoofing"
"Color LBP","Color LBP","face anti-spoofing based on color texture analysis"
"DLDL+VGG-Face","DLDL+VGG-Face","Deep Label Distribution Learning with Label Ambiguity"
"CMAAE-OR","CMAAE-OR","Facial Aging and Rejuvenation by Conditional Multi-Adversarial Autoencoder with Ordinal Regression"
"CORAL","CORAL","Consistent Rank Logits for Ordinal Regression with Convolutional Neural Networks"
"SAN GT","SAN GT","Style Aggregated Network for Facial Landmark Detection"
"Pose-Invariant","Pose-Invariant","Pose-Invariant Face Alignment with a Single CNN"
"FPN","FPN","FacePoseNet: Making a Case for Landmark-Free Face Alignment"
"SAN","SAN","Style Aggregated Network for Facial Landmark Detection"
"PRN","PRN","Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network"
"VRN-Guided","VRN-Guided","Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression"
"GANFit","GANFit","GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction"
"Unsupervised-3DMMR","Unsupervised-3DMMR","Unsupervised Training for 3D Morphable Model Regression"
"itwmm","itwmm","3D Face Morphable Models In-the-Wild"
"3DMM-CNN","3DMM-CNN","Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network"
"DeFA","DeFA","Dense Face Alignment"
"Deep Residual Equivariant Mapping","Deep Residual Equivariant Mapping","Pose-Robust Face Recognition via Deep Residual Equivariant Mapping"
"ArcFace + MS1MV2 + R100 + R","ArcFace + MS1MV2 + R100 + R","ArcFace: Additive Angular Margin Loss for Deep Face Recognition"
"CosFace","CosFace","CosFace: Large Margin Cosine Loss for Deep Face Recognition"
"SphereFace (3-patch ensemble)","SphereFace (3-patch ensemble)","SphereFace: Deep Hypersphere Embedding for Face Recognition"
"Light CNN-29","Light CNN-29","A Light CNN for Deep Face Representation with Noisy Labels"
"SphereFace (single model)","SphereFace (single model)","SphereFace: Deep Hypersphere Embedding for Face Recognition"
"FaceNet","FaceNet","FaceNet: A Unified Embedding for Face Recognition and Clustering"
"Deep CNN","Deep CNN","Deep Learning For Smile Recognition"
"Covariance Pooling","Covariance Pooling","Covariance Pooling For Facial Expression Recognition"
"Sequential forward selection","Sequential forward selection","Greedy Search for Descriptive Spatial Face Features"
"DeXpression","DeXpression","DeXpression: Deep Convolutional Neural Network for Expression Recognition"
"DAN-Menpo + bounding box diagonal normalization","DAN-Menpo + bounding box diagonal normalization","Deep Alignment Network: A convolutional neural network for robust face alignment"
"SIR-LAN","SIR-LAN","Facial Landmarks Detection by Self-Iterative Regression based Landmarks-Attention Network"
"DAN-Menpo + inter-ocular normalization","DAN-Menpo + inter-ocular normalization","Deep Alignment Network: A convolutional neural network for robust face alignment"
"LAB + Oracle + Inter-ocular Normalisation","LAB + Oracle + Inter-ocular Normalisation","Look at Boundary: A Boundary-Aware Face Alignment Algorithm"
"2DASL","2DASL","Joint 3D Face Reconstruction and Dense Face Alignment from A Single Image with 2D-Assisted Self-Supervised Learning"
"3DSTN","3DSTN","Faster Than Real-time Facial Alignment: A 3D Spatial Transformer Network Approach in Unconstrained Poses"
"3DDFA + SDM","3DDFA + SDM","Face Alignment Across Large Poses: A 3D Solution"
"FPN","FPN","Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network"
"Nonlinear 3D Face Morphable Model","Nonlinear 3D Face Morphable Model","Nonlinear 3D Face Morphable Model"
"MCL","MCL","Deep Multi-Center Learning for Face Alignment"
"DisguiseNet","DisguiseNet","DisguiseNet : A Contrastive Approach for Disguised Face Verification in the Wild"
"VGG-Face model features + cosine similarity metric","VGG-Face model features + cosine similarity metric","Recognizing Disguised Faces in the Wild"
"Dual-Agent GANs","Dual-Agent GANs","Dual-Agent GANs for Photorealistic and Identity Preserving Profile Face Synthesis"
"L2-constrained softmax loss","L2-constrained softmax loss","L2-constrained Softmax Loss for Discriminative Face Verification"
"NAN","NAN","Neural Aggregation Network for Video Face Recognition"
"Template adaptation","Template adaptation","Template Adaptation for Face Verification and Identification"
"All-in-one CNN","All-in-one CNN","An All-In-One Convolutional Neural Network for Face Analysis"
"Triplet probabilistic embedding","Triplet probabilistic embedding","Triplet Probabilistic Embedding for Face Verification and Clustering"
"Synthesis as data augmentation","Synthesis as data augmentation","Do We Really Need to Collect Millions of Faces for Effective Face Recognition?"
"DCNN","DCNN","Unconstrained Face Verification using Deep CNN Features"
"Deep multi-pose representations","Deep multi-pose representations","Face Recognition Using Deep Multi-Pose Representations"
"Deep CNN + COTS matcher","Deep CNN + COTS matcher","Face Search at Scale: 80 Million Gallery"
"AIM","AIM","Look Across Elapse: Disentangled Representation Learning and Photorealistic Cross-Age Face Synthesis for Age-Invariant Face Recognition"
"MN-vc","MN-vc","Multicolumn Networks for Face Recognition"
"SeqFace, 1 ResNet-64","SeqFace, 1 ResNet-64","SeqFace: Make full use of sequence information for face recognition"
"ArcFace + MS1MV2 + R100, ","ArcFace + MS1MV2 + R100, ","ArcFace: Additive Angular Margin Loss for Deep Face Recognition"
"QAN","QAN","Quality Aware Network for Set to Set Recognition"
"Git Loss","Git Loss","Git Loss for Deep Face Recognition"
"SphereFace","SphereFace","SphereFace: Deep Hypersphere Embedding for Face Recognition"
"DeepId2+","DeepId2+","Deeply learned face representations are sparse, selective, and robust"
"3DMM face shape parameters + CNN","3DMM face shape parameters + CNN","Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network"
"Ring loss","Ring loss","Ring loss: Convex Feature Normalization for Face Recognition"
"DeepId2","DeepId2","Deep Learning Face Representation by Joint Identification-Verification"
"SeqFace","SeqFace","SeqFace: Make full use of sequence information for face recognition"
"GaussianFace","GaussianFace","Surpassing Human-Level Face Verification Performance on LFW with GaussianFace"
"FAN","FAN","Face Attention Network: An Effective Face Detector for the Occluded Faces"
"AOFD","AOFD","Adversarial Occlusion-aware Face Detection"
"SRN","SRN","Selective Refinement Network for High Performance Face Detection"
"S3FD","S3FD","S$^3$FD: Single Shot Scale-invariant Face Detector"
"Anchor-based","Anchor-based","Robust Face Detection via Learning Small Faces on Hard Images"
"HyperFace-ResNet","HyperFace-ResNet","HyperFace: A Deep Multi-task Learning Framework for Face Detection, Landmark Localization, Pose Estimation, and Gender Recognition"
"LRN + RSA","LRN + RSA","Recurrent Scale Approximation for Object Detection in CNN"
"FaceBoxes","FaceBoxes","FaceBoxes: A CPU Real-time Face Detector with High Accuracy"
"STN","STN","Supervised Transformer Network for Efficient Face Detection"
"DPM","DPM","A Fast and Accurate Unconstrained Face Detector"
"Conv3D","Conv3D","Face Detection with End-to-End Integration of a ConvNet and a 3D Model"
"DSFD","DSFD","DSFD: Dual Shot Face Detector"
"PyramidBox","PyramidBox","PyramidBox: A Context-assisted Single Shot Face Detector"
"FDNet","FDNet","Face Detection Using Improved Faster RCNN"
"Face R-FCN","Face R-FCN","Detecting Faces Using Region-based Fully Convolutional Networks"
"Massively-large receptive fields","Massively-large receptive fields","Finding Tiny Faces"
"CMS-RCNN","CMS-RCNN","CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection"
"Multitask Cascade CNN","Multitask Cascade CNN","Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks"
"LDCF+","LDCF+","To Boost or Not to Boost? On the Limits of Boosted Trees for Object Detection"
"Faceness-WIDER","Faceness-WIDER","WIDER FACE: A Face Detection Benchmark"
"Multiscale Cascade CNN","Multiscale Cascade CNN","WIDER FACE: A Face Detection Benchmark"
"ACF-WIDER","ACF-WIDER","Aggregate channel features for multi-view face detection"
"Two-stage CNN","Two-stage CNN","WIDER FACE: A Face Detection Benchmark"
"MSCNN","MSCNN","A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection"
"HyperFace","HyperFace","HyperFace: A Deep Multi-task Learning Framework for Face Detection, Landmark Localization, Pose Estimation, and Gender Recognition"
"AIM + CAFR","AIM + CAFR","Look Across Elapse: Disentangled Representation Learning and Photorealistic Cross-Age Face Synthesis for Age-Invariant Face Recognition"
"OE-CNN","OE-CNN","Orthogonal Deep Features Decomposition for Age-Invariant Face Recognition"
"Light CNN","Light CNN","A Light CNN for Deep Face Representation with Noisy Labels"
"DeepVisage","DeepVisage","DeepVisage: Making face recognition simple yet with powerful generalization skills"
"MFM-CNN","MFM-CNN","A Light CNN for Deep Face Representation with Noisy Labels"
"SE-GV-3","SE-GV-3","GhostVLAD for set-based face recognition"
"GhostVLAD, SE-GV-3","GhostVLAD, SE-GV-3","GhostVLAD for set-based face recognition"
"SRGAN + Residual-in-Residual Dense Block","SRGAN + Residual-in-Residual Dense Block","ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks"
"ProSR","ProSR","A Fully Progressive Approach to Single-Image Super-Resolution"
"RCAN","RCAN","Image Super-Resolution Using Very Deep Residual Channel Attention Networks"
"EDSR","EDSR","Enhanced Deep Residual Networks for Single Image Super-Resolution"
"RDN","RDN","Residual Dense Network for Image Super-Resolution"
"SRFBN","SRFBN","Feedback Network for Image Super-Resolution"
"Manifold Simplification","Manifold Simplification","Beyond Deep Residual Learning for Image Restoration: Persistent Homology-Guided Manifold Simplification"
"CARN","CARN","Fast, Accurate, and Lightweight Super-Resolution with Cascading Residual Network"
"SRRAM","SRRAM","RAM: Residual Attention Module for Single Image Super-Resolution"
"BSRN","BSRN","Lightweight and Efficient Image Super-Resolution with Block State-based Recursive Network"
"SRMDNF","SRMDNF","Learning a Single Convolutional Super-Resolution Network for Multiple Degradations"
"ENet-E","ENet-E","EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis"
"RL-CSC","RL-CSC","Image Super-Resolution via RL-CSC: When Residual Learning Meets Convolutional Sparse Coding"
"MemNet","MemNet","MemNet: A Persistent Memory Network for Image Restoration"
"SESR","SESR","SESR: Single Image Super Resolution with Recursive Squeeze and Excitation Networks"
"IDN","IDN","Fast and Accurate Single Image Super-Resolution via Information Distillation Network"
"LapSRN","LapSRN","Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution"
"DnCNN-3","DnCNN-3","Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising"
"DSRN","DSRN","Image Super-Resolution via Dual-State Recurrent Networks"
"bicubic","bicubic","ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks"
"D-DBPN","D-DBPN","Deep Back-Projection Networks For Super-Resolution"
"PFF","PFF","Image Reconstruction with Predictive Filter Flow"
"SRResNet","SRResNet","Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
" LapSR"," LapSR","Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution"
"DRCN","DRCN","Deeply-Recursive Convolutional Network for Image Super-Resolution"
"ZSSR","ZSSR","Zero-Shot Super-Resolution using Deep Internal Learning"
"IA","IA","Seven ways to improve example-based single image super resolution"
"MSSRNet","MSSRNet","Single Image Super-Resolution with Dilated Convolution based Multi-Scale Information Learning Inception Module"
"TNRD","TNRD","Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration"
"4PP-EUSR","4PP-EUSR","Deep Learning-based Image Super-Resolution Considering Quantitative and Perceptual Quality"
"SPMC","SPMC","Detail-revealing Deep Video Super-resolution"
"FAFR*","FAFR*","Image Super-resolution via Feature-augmented Random Forest"
"JMPF+","JMPF+","Joint Maximum Purity Forest with Application to Image Super-Resolution"
"Deep Mean-Shift Priors","Deep Mean-Shift Priors","Deep Mean-Shift Priors for Image Restoration"
"SFT-GAN","SFT-GAN","Recovering Realistic Texture in Image Super-resolution by Deep Spatial Feature Transform"
"SRGAN","SRGAN","Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
"bicubic","bicubic","Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
"nearest neighbors","nearest neighbors","Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
"RED30","RED30","Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections"
"Perceptual Loss","Perceptual Loss","Perceptual Losses for Real-Time Style Transfer and Super-Resolution"
"FARF*","FARF*","Image Super-resolution via Feature-augmented Random Forest"
"FALSR-A ","FALSR-A ","Fast, Accurate and Lightweight Super-Resolution with Neural Architecture Search"
"Variational graph auto-encoders","Variational graph auto-encoders","Variational Graph Auto-Encoders"
"ComplEx-N3 (reciprocal)","ComplEx-N3 (reciprocal)","Canonical Tensor Decomposition for Knowledge Base Completion"
"ConvE","ConvE","Convolutional 2D Knowledge Graph Embeddings"
"M3GM","M3GM","Predicting Semantic Relations using Global Graph Properties"
"TuckER","TuckER","TuckER: Tensor Factorization for Knowledge Graph Completion"
"HypER","HypER","Hypernetwork Knowledge Graph Embeddings"
"M-Walk","M-Walk","M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search"
"SimplE","SimplE","SimplE Embedding for Link Prediction in Knowledge Graphs"
"Inverse Model","Inverse Model","Convolutional 2D Knowledge Graph Embeddings"
"ANALOGY","ANALOGY","Analogical Inference for Multi-Relational Embeddings"
"ComplEx","ComplEx","Complex Embeddings for Simple Link Prediction"
"DistMult","DistMult","Embedding Entities and Relations for Learning and Inference in Knowledge Bases"
"Gaifman","Gaifman","Discriminative Gaifman Models"
"SMT + NMT (tuning and joint refinement)","SMT + NMT (tuning and joint refinement)","An Effective Approach to Unsupervised Machine Translation"
"MLM pretraining for encoder and decoder","MLM pretraining for encoder and decoder","Cross-lingual Language Model Pretraining"
"SMT as posterior regularization","SMT as posterior regularization","Unsupervised Neural Machine Translation with SMT as Posterior Regularization"
"PBSMT + NMT","PBSMT + NMT","Phrase-Based & Neural Unsupervised Machine Translation"
"Synthetic bilingual data init","Synthetic bilingual data init","Unsupervised Neural Machine Translation Initialized by Unsupervised Statistical Machine Translation"
"PBSMT","PBSMT","Phrase-Based & Neural Unsupervised Machine Translation"
"SMT","SMT","Unsupervised Statistical Machine Translation"
"universal transformer base","universal transformer base","Universal Transformers"
"MLM pretraining","MLM pretraining","Cross-lingual Language Model Pretraining"
"Attentional encoder-decoder + BPE","Attentional encoder-decoder + BPE","Edinburgh Neural Machine Translation Systems for WMT 16"
"NAT +FT + NPD","NAT +FT + NPD","Non-Autoregressive Neural Machine Translation"
"Denoising autoencoders (non-autoregressive)","Denoising autoencoders (non-autoregressive)","Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement"
"Seq-KD + Seq-Inter + Word-KD","Seq-KD + Seq-Inter + Word-KD","Sequence-Level Knowledge Distillation"
"C2-50k Segmentation","C2-50k Segmentation","Neural Machine Translation of Rare Words with Subword Units"
"Pervasive Attention","Pervasive Attention","Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction"
"Transformer with FRAGE","Transformer with FRAGE","FRAGE: Frequency-Agnostic Word Representation"
"Variational Attention","Variational Attention","Latent Alignment and Variational Attention"
"ConvS2S+Risk","ConvS2S+Risk","Classical Structured Prediction Losses for Sequence to Sequence Learning"
"ConvS2S (MLE+SLE)","ConvS2S (MLE+SLE)","Classical Structured Prediction Losses for Sequence to Sequence Learning"
"ConvS2S","ConvS2S","Convolutional Sequence to Sequence Learning"
"Conv-LSTM (deep+pos)","Conv-LSTM (deep+pos)","A Convolutional Encoder Model for Neural Machine Translation"
"NPMT + language model","NPMT + language model","Towards Neural Phrase-based Machine Translation"
"RNNsearch","RNNsearch","An Actor-Critic Algorithm for Sequence Prediction"
"DCCL","DCCL","Compressing Word Embeddings via Deep Compositional Code Learning"
"Bi-GRU (MLE+SLE)","Bi-GRU (MLE+SLE)","Neural Machine Translation by Jointly Learning to Align and Translate"
"Word-level CNN wattn, input feeding","Word-level CNN wattn, input feeding","Sequence-to-Sequence Learning as Beam-Search Optimization"
"Word-level LSTM wattn","Word-level LSTM wattn","Sequence Level Training with Recurrent Neural Networks"
"QRNN","QRNN","Quasi-Recurrent Neural Networks"
"SMT + iterative backtranslation (unsupervised)","SMT + iterative backtranslation (unsupervised)","Unsupervised Statistical Machine Translation"
"Linguistic Input Features","Linguistic Input Features","Linguistic Input Features Improve Neural Machine Translation"
"Unsupervised NMT + weight-sharing","Unsupervised NMT + weight-sharing","Unsupervised Neural Machine Translation with Weight Sharing"
"Unsupervised S2S with attention","Unsupervised S2S with attention","Unsupervised Machine Translation Using Monolingual Corpora Only"
"ByteNet","ByteNet","Neural Machine Translation in Linear Time"
"S2Tree+5gram NPLM","S2Tree+5gram NPLM",""
"Enc-Dec Att (char)","Enc-Dec Att (char)","A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation"
"BPE word segmentation","BPE word segmentation","Neural Machine Translation of Rare Words with Subword Units"
"Enc-Dec Att (BPE)","Enc-Dec Att (BPE)","A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation"
"Unsupervised attentional encoder-decoder + BPE","Unsupervised attentional encoder-decoder + BPE","Unsupervised Neural Machine Translation"
"DeepL","DeepL",""
"Transformer Big","Transformer Big","Scaling Neural Machine Translation"
"Evolved Transformer Big","Evolved Transformer Big","The Evolved Transformer"
"Transformer (big) + Relative Position Representations","Transformer (big) + Relative Position Representations","Self-Attention with Relative Position Representations"
"Transformer Big with FRAGE","Transformer Big with FRAGE","FRAGE: Frequency-Agnostic Word Representation"
"Weighted Transformer (large)","Weighted Transformer (large)","Weighted Transformer Network for Machine Translation"
"LightConv","LightConv","Pay Less Attention with Lightweight and Dynamic Convolutions"
"Evolved Transformer Base","Evolved Transformer Base","The Evolved Transformer"
"Transformer Big","Transformer Big","Attention Is All You Need"
"Transformer + SRU","Transformer + SRU","Simple Recurrent Units for Highly Parallelizable Recurrence"
"Transformer Base","Transformer Base","Attention Is All You Need"
"ConvS2S (ensemble)","ConvS2S (ensemble)","Convolutional Sequence to Sequence Learning"
"GNMT+RL","GNMT+RL","Googles Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
"SliceNet","SliceNet","Depthwise Separable Convolutions for Neural Machine Translation"
"MoE","MoE","Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
"Deep-Att","Deep-Att","Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation"
"PBMT","PBMT",""
"Unsupervised PBSMT","Unsupervised PBSMT","Phrase-Based & Neural Unsupervised Machine Translation"
"NSE-NSE","NSE-NSE","Neural Semantic Encoders"
"Unsupervised NMT + Transformer","Unsupervised NMT + Transformer","Phrase-Based & Neural Unsupervised Machine Translation"
"RNMT+","RNMT+","The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation"
"ConvS2S BPE40k","ConvS2S BPE40k","Convolutional Sequence to Sequence Learning"
"GRU BPE90k","GRU BPE90k","The QT21HimL Combined Machine Translation System"
"BiGRU","BiGRU","Edinburgh Neural Machine Translation Systems for WMT 16"
"Deep Convolutional Encoder; single-layer decoder","Deep Convolutional Encoder; single-layer decoder","A Convolutional Encoder Model for Neural Machine Translation"
"BiLSTM","BiLSTM","A Convolutional Encoder Model for Neural Machine Translation"
"Transformer Big + BT","Transformer Big + BT","Understanding Back-Translation at Scale"
"Deep-Att + PosUnk","Deep-Att + PosUnk","Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation"
"LSTM6 + PosUnk","LSTM6 + PosUnk","Addressing the Rare Word Problem in Neural Machine Translation"
"SMT+LSTM5","SMT+LSTM5","Sequence to Sequence Learning with Neural Networks"
"RNN-search50*","RNN-search50*","Neural Machine Translation by Jointly Learning to Align and Translate"
"LSTM","LSTM","Sequence to Sequence Learning with Neural Networks"
"CSLM + RNN + WP","CSLM + RNN + WP","Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation"
"Regularized LSTM","Regularized LSTM","Recurrent Neural Network Regularization"
"GRU+Attention","GRU+Attention","Can Active Memory Replace Attention?"
"Support Vector Machines","Support Vector Machines","Inferring hybrid transportation modes from sparse GPS data using a moving window SVM classification"
"TF-KLD","TF-KLD",""
"Oracle IR Models","Oracle IR Models","The NarrativeQA Reading Comprehension Challenge"
